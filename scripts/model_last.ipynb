{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ABSA Model (최종 버전)\n",
        "\n",
        "- kykim/electra-kor-base : ACD\n",
        "- klue/roberta-base : ASC\n",
        "- back translation & stratifiedKFold 적용\n",
        "- spacing 적용\n",
        "- max_len = 128 로 수정"
      ],
      "metadata": {
        "id": "O4oJ0t9qEQG1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2609,
          "status": "ok",
          "timestamp": 1749183527192,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          },
          "user_tz": -540
        },
        "id": "_RDH-YQsQ2K0",
        "outputId": "c62e2f4d-82fd-47a0-8491-4e9018cd9718",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2517,
          "status": "ok",
          "timestamp": 1749183529714,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          },
          "user_tz": -540
        },
        "id": "gmtfOHQSQ-nS",
        "outputId": "dba9ebd6-fa57-412a-f325-1023db0340c9",
        "scrolled": true,
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIpyIPxkdgFC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749384450321,
          "user_tz": -540,
          "elapsed": 20737,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "c86b2527-d0c6-4e8b-843a-b2c831c0bb34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jprcZhTyetFF"
      },
      "source": [
        "# 모듈 import 및 전역 변수 설정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import trange, tqdm\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.optim import AdamW\n",
        "from torch.amp import autocast, GradScaler\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "WymivmdMeksE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LDwADWNMpsC"
      },
      "outputs": [],
      "source": [
        "PADDING_TOKEN = 0\n",
        "S_OPEN_TOKEN = 1\n",
        "S_CLOSE_TOKEN = 2\n",
        "\n",
        "do_eval=True\n",
        "\n",
        "# 경로 설정\n",
        "BASE_DIR = '/content/drive/MyDrive/ABSA'\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "SAVED_MODEL_DIR = os.path.join(BASE_DIR, 'saved_model')\n",
        "ACD_MODEL_DIR = os.path.join(BASE_DIR, 'saved_model/ACD')\n",
        "ASC_MODEL_DIR = os.path.join(BASE_DIR, 'saved_model/ASC')\n",
        "pred_result_DIR = os.path.join(BASE_DIR, 'pred_result')\n",
        "final_output_DIR = os.path.join(BASE_DIR, 'final_output')\n",
        "\n",
        "base_data_path = os.path.join(DATA_DIR, 'base_data.jsonl')\n",
        "converted_base_data_path = os.path.join(DATA_DIR, 'converted_base_data.jsonl')\n",
        "\n",
        "train_data_path = os.path.join(DATA_DIR, 'train.jsonl')\n",
        "dev_data_path = os.path.join(DATA_DIR, 'dev.jsonl')\n",
        "test_data_path = os.path.join(DATA_DIR, 'test.jsonl')\n",
        "\n",
        "acd_best_model_path = os.path.join(ACD_MODEL_DIR, 'best_model_last.pt')\n",
        "asc_best_model_path = os.path.join(ASC_MODEL_DIR, 'best_model_last.pt')\n",
        "\n",
        "raw_data_path = os.path.join(DATA_DIR, 'rawdata_spaced_final.jsonl')\n",
        "converted_raw_data_path = os.path.join(DATA_DIR, 'converted_raw_data.jsonl')\n",
        "final_output_path = os.path.join(final_output_DIR, 'final_spaced_output.jsonl')\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "max_len = 128\n",
        "batch_size = 16\n",
        "acd_base_model = 'kykim/electra-kor-base'\n",
        "asc_base_model = 'klue/roberta-base'\n",
        "learning_rate = 3e-6\n",
        "eps = 1e-8\n",
        "num_train_epochs = 30\n",
        "dropout_prob = 0.1\n",
        "label_smoothing = 0.1\n",
        "max_grad_norm = 1.0\n",
        "threshold = 0.95\n",
        "\n",
        "# 속성 카테고리 정의\n",
        "entity_property_pair = [\n",
        "    '세정', '자극', '거품', '향', '가격', '머릿결', '탈모', '쿨링'\n",
        "]\n",
        "\n",
        "# ACD 라벨 (multi-label classification)\n",
        "tf_id_to_name = ['False', 'True']\n",
        "tf_name_to_id = {name: idx for idx, name in enumerate(tf_id_to_name)}\n",
        "\n",
        "# ASC 라벨 (multi-class classification)\n",
        "polarity_id_to_name = ['positive', 'negative', 'neutral']\n",
        "polarity_name_to_id = {name: idx for idx, name in enumerate(polarity_id_to_name)}\n",
        "\n",
        "# device 정의\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# special_tokens 정의\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': [\n",
        "        '&name&', '&affiliation&',\n",
        "        '&social-security-num&',\n",
        "        '&tel-num&', '&card-num&', '&bank-account&',\n",
        "        '&num&', '&online-account&'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGmH15hCeqhJ"
      },
      "source": [
        "json 및 jsonl 파일 read, write 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vGeHU4yP2Sg",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def jsonload(fname, encoding=\"utf-8\"):\n",
        "    with open(fname, encoding=encoding) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# json 객체를 파일이름으로 깔끔하게 저장\n",
        "def jsondump(j, fname):\n",
        "    with open(fname, \"w\", encoding=\"UTF8\") as f:\n",
        "        json.dump(j, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# jsonl 파일 읽어서 list에 저장\n",
        "def jsonlload(fname_list, encoding=\"utf-8\"):\n",
        "    if isinstance(fname_list, str):\n",
        "        fname_list = [fname_list]\n",
        "\n",
        "    json_list = []\n",
        "    for fname in fname_list:\n",
        "        path = fname if os.path.isfile(fname) else os.path.join(DATA_DIR, fname)\n",
        "        with open(path, encoding=encoding) as f:\n",
        "            for line in f:\n",
        "                json_list.append(json.loads(line))\n",
        "    return json_list\n",
        "\n",
        "# list에 담긴 json 객체를 jsonl 파일에 저장\n",
        "def jsonldump(jlist, fname):\n",
        "    with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
        "        for item in jlist:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# jsonl 파일에서 불러온 데이터 분할\n",
        "def split_jsonl_file(jsonl_path, output_dir, train_ratio=0.7, dev_ratio=0.15, test_ratio=0.15, seed=42):\n",
        "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
        "        lines = [json.loads(line) for line in f]\n",
        "\n",
        "    train_data, temp_data = train_test_split(lines, test_size=(1 - train_ratio), random_state=seed)\n",
        "    dev_data, test_data = train_test_split(temp_data, test_size=test_ratio / (dev_ratio + test_ratio), random_state=seed)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    jsonldump(train_data, os.path.join(output_dir, 'train.jsonl'))\n",
        "    jsonldump(dev_data, os.path.join(output_dir, 'dev.jsonl'))\n",
        "    jsonldump(test_data, os.path.join(output_dir, 'test.jsonl'))\n",
        "\n",
        "    print(f\"데이터 분할 완료: train={len(train_data)}, dev={len(dev_data)}, test={len(test_data)}\")\n",
        "\n",
        "def split_jsonl_file_train_dev_only(jsonl_path, output_dir, train_ratio=0.85, dev_ratio=0.15, seed=42):\n",
        "    assert abs(train_ratio + dev_ratio - 1.0) < 1e-6, \"train과 dev의 비율 합이 1이 되어야 합니다.\"\n",
        "\n",
        "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
        "        lines = [json.loads(line) for line in f]\n",
        "\n",
        "    train_data, dev_data = train_test_split(lines, test_size=dev_ratio, random_state=seed)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    jsonldump(train_data, os.path.join(output_dir, 'train.jsonl'))\n",
        "    jsonldump(dev_data, os.path.join(output_dir, 'dev.jsonl'))\n",
        "\n",
        "    print(f\"데이터 분할 완료: train={len(train_data)}, dev={len(dev_data)}\")\n",
        "\n",
        "def ensure_annotation(data):\n",
        "    for sample in data:\n",
        "        if not sample.get(\"annotation\") or sample[\"annotation\"] == []:\n",
        "            sample[\"annotation\"] = [[\"없음\", [None, 0, 0], None]]\n",
        "    return data\n",
        "\n",
        "def truncate_left(input_ids, attention_mask, max_len, pad_token_id=0):\n",
        "    if len(input_ids) > max_len:\n",
        "        input_ids = input_ids[-max_len:]\n",
        "        attention_mask = attention_mask[-max_len:]\n",
        "    else:\n",
        "        pad_len = max_len - len(input_ids)\n",
        "        input_ids = input_ids + [pad_token_id] * pad_len\n",
        "        attention_mask = attention_mask + [0] * pad_len\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "def convert_to_absa_format(data):\n",
        "    converted = []\n",
        "    sentiment_map = {\"긍정\": \"positive\", \"부정\": \"negative\", \"중립\": \"neutral\"}\n",
        "\n",
        "    for item in data:\n",
        "        sentence = item.get(\"text\", \"\")\n",
        "        label_list = item.get(\"entities\") or item.get(\"label\") or []\n",
        "        annos = []\n",
        "\n",
        "        for label_item in label_list:\n",
        "            try:\n",
        "                start, end, full_label = label_item\n",
        "                word = sentence[start:end]\n",
        "\n",
        "                if \"-\" not in full_label:\n",
        "                    continue\n",
        "\n",
        "                aspect, sentiment_ko = full_label.split(\"-\")\n",
        "\n",
        "                if aspect not in entity_property_pair:\n",
        "                    continue\n",
        "\n",
        "                polarity = sentiment_map.get(sentiment_ko.strip())\n",
        "                if polarity is None:\n",
        "                    continue\n",
        "\n",
        "                annos.append([aspect, [word, start, end], polarity])\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        converted.append({\n",
        "            \"sentence_form\": sentence,\n",
        "            \"annotation\": annos\n",
        "        })\n",
        "\n",
        "    return converted"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_data = jsonlload(base_data_path)\n",
        "converted_base_data = convert_to_absa_format(base_data)\n",
        "jsonldump(converted_base_data, converted_base_data_path)\n",
        "jsonlload(converted_base_data_path)"
      ],
      "metadata": {
        "id": "sb68_u6qg5ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PALW718Gb0WA"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_2Ckbwab0WB"
      },
      "source": [
        "- len 200 이하로 자르고 띄어쓰기 수행하는데, 속성 주변 기준으로 리뷰 자르게 되면\n",
        "    - truncate_and_spacing 수정 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdfMW5hdb0WB"
      },
      "outputs": [],
      "source": [
        "# 1. 한글, 영어, 숫자, 공백, 직접 정한 허가 특수문자들 이외 공백처리\n",
        "def clean_review(text):\n",
        "    allowed_punctuations = \"!?.,%+=~&()\"\n",
        "    pattern = rf\"[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9\\s{re.escape(allowed_punctuations)}]\"\n",
        "\n",
        "    text = re.sub(pattern, ' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 2. 소괄호 안 부연설명 삭제\n",
        "def del_bracket(text):\n",
        "    # 괄호 안 부연설명 제거 (중첩 괄호 포함)\n",
        "    while re.search(r'\\([^()]*\\)', text):\n",
        "        text = re.sub(r'\\([^()]*\\)', ' ', text)\n",
        "\n",
        "    # 잔여 괄호 제거\n",
        "    text = text.replace(\"(\", \" \")\n",
        "    text = text.replace(\")\", \" \")\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 3. 의미없는 반복 문자열 축약\n",
        "# 반복어구\n",
        "dupchars_pattern = re.compile(r'(.)\\1{2,}')\n",
        "dupsymbols_pattern = re.compile(r'([!?~%+=&])\\1{1,}')\n",
        "# 더블스페이스\n",
        "doublespace_pattern = re.compile(r'\\s+')\n",
        "\n",
        "def contract_dupchars(text, n = 3):\n",
        "    if n > 0:\n",
        "        text = dupchars_pattern.sub('\\\\1' * n, text)\n",
        "\n",
        "    text = dupsymbols_pattern.sub('\\\\1', text)\n",
        "    text = doublespace_pattern.sub(' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 4. 협찬 문장 제거\n",
        "def del_sponsored(text):\n",
        "    sponsored_pattern = r'''\n",
        "        (판매자(에게|로부터)|업체로부터|본\\s상품\\s후기는).{0,70}?\n",
        "        (후기(입니다|입니다타|에요|입니\\s?다)?|\n",
        "         리뷰(입니다|했습니다|적었습니다|하였습니다|입니다요)?|\n",
        "         작성하였습니다|기남겨요|기랍니다|흐기입니다|전달합니다|올립니다|것\\s?입니다)\n",
        "        [!.~\\s]{0,2}\n",
        "    '''\n",
        "    sponsored_pattern = re.compile(sponsored_pattern, flags=re.VERBOSE)\n",
        "    text = sponsored_pattern.sub(' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 전처리 종합\n",
        "def preprocessing(form):\n",
        "    form = clean_review(form)\n",
        "    form = del_bracket(form)\n",
        "    form = contract_dupchars(form)\n",
        "    form = del_sponsored(form)\n",
        "\n",
        "    return form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMcYnIo3b0WC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuHV8HGqXvg_"
      },
      "source": [
        "# 모델 정의\n",
        "\n",
        "- ACD 를 위한 ky-kim/electra-kor-base\n",
        "- ASC 를 위한 klue/roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJGY-OErb0WD"
      },
      "outputs": [],
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        scores = self.attention(hidden_states).squeeze(-1)\n",
        "        scores = scores.masked_fill(attention_mask == 0, -1e4)\n",
        "        weights = torch.softmax(scores, dim=-1)\n",
        "        pooled = torch.sum(hidden_states * weights.unsqueeze(-1), dim=1)\n",
        "        return pooled\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size, num_labels, dropout_prob=dropout_prob):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "        self.norm = nn.LayerNorm(hidden_size)\n",
        "        self.act = nn.Tanh()\n",
        "        self.output = nn.Linear(hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.output(x)\n",
        "\n",
        "class ABSA_Model(nn.Module):\n",
        "    def __init__(self, base_model, num_labels, tokenizer_len=None, dropout_prob=dropout_prob):\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(base_model)\n",
        "        self.backbone = AutoModel.from_pretrained(base_model, config=config)\n",
        "\n",
        "        if tokenizer_len is not None:\n",
        "            self.backbone.resize_token_embeddings(tokenizer_len)\n",
        "\n",
        "        self.attn_pool = AttentionPooling(config.hidden_size)\n",
        "        self.classifier = SimpleClassifier(config.hidden_size, num_labels, dropout_prob)\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.backbone(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        hidden_states = outputs.last_hidden_state\n",
        "        pooled_output = self.attn_pool(hidden_states, attention_mask)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return None, logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CumM58YTb0WD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-p0LKeGi194"
      },
      "source": [
        "# 데이터 파싱 및 tokenization 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO-hv7lQQGA5"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(tokenizer, form, annotations, max_len):\n",
        "    entity_dict = {'input_ids': [], 'attention_mask': [], 'label': []}\n",
        "    polarity_dict = {'input_ids': [], 'attention_mask': [], 'label': []}\n",
        "\n",
        "    if not form or not isinstance(form, str):\n",
        "        return entity_dict, polarity_dict\n",
        "\n",
        "    pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
        "\n",
        "    for pair in entity_property_pair:\n",
        "        matched = False\n",
        "\n",
        "        encoded = tokenizer(\n",
        "            form,\n",
        "            pair,\n",
        "            padding=False,\n",
        "            truncation=False,\n",
        "            return_tensors='pt',\n",
        "            add_special_tokens=True\n",
        "        )\n",
        "\n",
        "        input_ids = encoded['input_ids'][0].tolist()\n",
        "        attention_mask = encoded['attention_mask'][0].tolist()\n",
        "        input_ids, attention_mask = truncate_left(input_ids, attention_mask, max_len, pad_token_id)\n",
        "\n",
        "        for annotation in annotations:\n",
        "            if len(annotation) < 3:\n",
        "                continue\n",
        "\n",
        "            entity_property, _, polarity = annotation\n",
        "            if polarity == '------------':\n",
        "                continue\n",
        "\n",
        "            if entity_property != '없음' and entity_property == pair:\n",
        "                entity_dict['input_ids'].append(input_ids)\n",
        "                entity_dict['attention_mask'].append(attention_mask)\n",
        "                entity_dict['label'].append(tf_name_to_id['True'])\n",
        "\n",
        "                polarity_id = polarity_name_to_id.get(polarity)\n",
        "                if polarity_id is not None:\n",
        "                    polarity_dict['input_ids'].append(input_ids)\n",
        "                    polarity_dict['attention_mask'].append(attention_mask)\n",
        "                    polarity_dict['label'].append(polarity_id)\n",
        "\n",
        "                matched = True\n",
        "                break\n",
        "\n",
        "        if not matched:\n",
        "            entity_dict['input_ids'].append(input_ids)\n",
        "            entity_dict['attention_mask'].append(attention_mask)\n",
        "            entity_dict['label'].append(tf_name_to_id['False'])\n",
        "\n",
        "    return entity_dict, polarity_dict\n",
        "\n",
        "def get_dataset(raw_data, tokenizer, max_len):\n",
        "    entity_inputs, entity_masks, entity_labels = [], [], []\n",
        "    polarity_inputs, polarity_masks, polarity_labels = [], [], []\n",
        "\n",
        "    for utterance in raw_data:\n",
        "        form = utterance.get('sentence_form', '')\n",
        "        form = preprocessing(form)\n",
        "        if len(form) < 10:\n",
        "            continue\n",
        "        annotations = utterance.get('annotation', [])\n",
        "\n",
        "        entity_dict, polarity_dict = tokenize_and_align_labels(tokenizer, form, annotations, max_len)\n",
        "\n",
        "        entity_inputs.extend(entity_dict['input_ids'])\n",
        "        entity_masks.extend(entity_dict['attention_mask'])\n",
        "        entity_labels.extend(entity_dict['label'])\n",
        "\n",
        "        polarity_inputs.extend(polarity_dict['input_ids'])\n",
        "        polarity_masks.extend(polarity_dict['attention_mask'])\n",
        "        polarity_labels.extend(polarity_dict['label'])\n",
        "\n",
        "    if not entity_inputs:\n",
        "        raise ValueError(\"No entity data found. Check preprocessing or filtering conditions.\")\n",
        "    if not polarity_inputs:\n",
        "        raise ValueError(\"No polarity data found. Check preprocessing or filtering conditions.\")\n",
        "\n",
        "    def compute_class_weight(labels, label_size):\n",
        "        counter = Counter(labels)\n",
        "        total = sum(counter.values())\n",
        "        return torch.tensor([\n",
        "            (total / count) if count > 0 else 0.0\n",
        "            for i in range(label_size)\n",
        "            for count in [counter.get(i, 0)]\n",
        "        ], dtype=torch.float)\n",
        "\n",
        "    entity_dataset = TensorDataset(\n",
        "        torch.tensor(entity_inputs, dtype=torch.long),\n",
        "        torch.tensor(entity_masks, dtype=torch.long),\n",
        "        torch.tensor(entity_labels, dtype=torch.long)\n",
        "    )\n",
        "\n",
        "    polarity_dataset = TensorDataset(\n",
        "        torch.tensor(polarity_inputs, dtype=torch.long),\n",
        "        torch.tensor(polarity_masks, dtype=torch.long),\n",
        "        torch.tensor(polarity_labels, dtype=torch.long)\n",
        "    )\n",
        "\n",
        "    entity_weights = compute_class_weight(entity_labels, len(tf_name_to_id))\n",
        "    polarity_weights = compute_class_weight(polarity_labels, len(polarity_name_to_id))\n",
        "\n",
        "    return entity_dataset, polarity_dataset, entity_weights, polarity_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUtHTsXYb0WF"
      },
      "source": [
        "- tokenizer = acd_tokenizer or asc_tokenizer 로 task 에 맞게 할당\n",
        "\n",
        "- return 값 중 필요한 것만 쓰기\n",
        "    - 필요 없는 건 _ 로 무시"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ka98lsxi--Y"
      },
      "source": [
        "# 모델 학습 및 최적화\n",
        "\n",
        "- 콜백"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL0yp7zSaX9B"
      },
      "outputs": [],
      "source": [
        "def evaluation(y_true, y_pred, label_len):\n",
        "    count_list = [0] * label_len\n",
        "    hit_list = [0] * label_len\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        count_list[y_true[i]] += 1\n",
        "        if y_true[i] == y_pred[i]:\n",
        "            hit_list[y_true[i]] += 1\n",
        "\n",
        "    acc_list = [hit / count if count > 0 else 0 for hit, count in zip(hit_list, count_list)]\n",
        "    print(f'Accuracy: {sum(hit_list) / sum(count_list):.4f}')\n",
        "    print(f'Macro Accuracy: {sum(acc_list) / label_len:.4f}')\n",
        "    print('F1 (per class):', f1_score(y_true, y_pred, average=None))\n",
        "    print('F1 Micro:', f1_score(y_true, y_pred, average='micro'))\n",
        "    print('F1 Macro:', f1_score(y_true, y_pred, average='macro'))\n",
        "\n",
        "scaler = GradScaler()\n",
        "def train_one_epoch(model, dataloader, optimizer, scheduler, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_type=\"cuda\"):\n",
        "          loss, logits = model(input_ids, attention_mask, labels)\n",
        "          loss = loss_fn(logits, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    preds, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids, attention_mask, label_ids = [t.to(device) for t in batch]\n",
        "            _, logits = model(input_ids, attention_mask)\n",
        "            pred = torch.argmax(logits, dim=-1)\n",
        "            preds.extend(pred.tolist())\n",
        "            labels.extend(label_ids.tolist())\n",
        "\n",
        "    macro_f1 = f1_score(labels, preds, average='macro')\n",
        "    return macro_f1, preds, labels\n",
        "\n",
        "def get_optimizer_scheduler(model, dataloader):\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(grouped_parameters, lr=learning_rate, eps=eps)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,\n",
        "                                                num_training_steps=len(dataloader) * num_train_epochs)\n",
        "    return optimizer, scheduler\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=4, mode='max'):\n",
        "        self.patience = patience\n",
        "        self.mode = mode\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.should_stop = False\n",
        "\n",
        "    def step(self, score):\n",
        "        if self.best_score is None or \\\n",
        "           (self.mode == 'max' and score > self.best_score) or \\\n",
        "           (self.mode == 'min' and score < self.best_score):\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.should_stop = True\n",
        "\n",
        "def train_sentiment_analysis(train_data, dev_data):\n",
        "\n",
        "    print('train_sentiment_analysis START')\n",
        "\n",
        "    acd_tokenizer = AutoTokenizer.from_pretrained(acd_base_model)\n",
        "    asc_tokenizer = AutoTokenizer.from_pretrained(asc_base_model)\n",
        "    acd_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    asc_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "    train_data = ensure_annotation(train_data)\n",
        "    dev_data = ensure_annotation(dev_data)\n",
        "\n",
        "    entity_train, _, entity_weights, _ = get_dataset(train_data, acd_tokenizer, max_len)\n",
        "    _, polarity_train, _, polarity_weights = get_dataset(train_data, asc_tokenizer, max_len)\n",
        "    entity_dev, _, _, _ = get_dataset(dev_data, acd_tokenizer, max_len)\n",
        "    _, polarity_dev, _, _ = get_dataset(dev_data, asc_tokenizer, max_len)\n",
        "\n",
        "    print(\"Entity Class Weights:\")\n",
        "    for i, (name, weight) in enumerate(zip(tf_id_to_name, entity_weights.tolist())):\n",
        "        print(f\"  - {name} (class {i}): weight = {weight:.4f}\")\n",
        "\n",
        "    print(\"Polarity Class Weights:\")\n",
        "    for i, (name, weight) in enumerate(zip(polarity_id_to_name, polarity_weights.tolist())):\n",
        "        print(f\"  - {name} (class {i}): weight = {weight:.4f}\")\n",
        "\n",
        "    entity_train_loader = DataLoader(entity_train, shuffle=True, batch_size=batch_size)\n",
        "    entity_dev_loader = DataLoader(entity_dev, shuffle=False, batch_size=batch_size)\n",
        "    polarity_train_loader = DataLoader(polarity_train, shuffle=True, batch_size=batch_size)\n",
        "    polarity_dev_loader = DataLoader(polarity_dev, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    entity_model = ABSA_Model(acd_base_model,  len(tf_name_to_id), len(acd_tokenizer)).to(device)\n",
        "    polarity_model = ABSA_Model(asc_base_model,  len(polarity_name_to_id), len(asc_tokenizer)).to(device)\n",
        "\n",
        "    entity_loss_fn = torch.nn.CrossEntropyLoss(weight=entity_weights.to(device))\n",
        "    polarity_loss_fn = torch.nn.CrossEntropyLoss(weight=polarity_weights.to(device))\n",
        "\n",
        "    entity_opt, entity_sched = get_optimizer_scheduler(entity_model, entity_train_loader)\n",
        "    polarity_opt, polarity_sched = get_optimizer_scheduler(polarity_model, polarity_train_loader)\n",
        "\n",
        "    early_stop_entity = EarlyStopping(patience=4, mode='max')\n",
        "    early_stop_polarity = EarlyStopping(patience=4, mode='max')\n",
        "\n",
        "    for epoch in trange(num_train_epochs, desc=\"Epoch\"):\n",
        "        entity_loss = train_one_epoch(entity_model, entity_train_loader, entity_opt, entity_sched, entity_loss_fn)\n",
        "        print(f\"[Entity] Epoch {epoch+1} | Train Loss: {entity_loss:.4f}\")\n",
        "\n",
        "        if do_eval:\n",
        "            f1, preds, labels = evaluate_model(entity_model, entity_dev_loader)\n",
        "            print(f\"[Entity] Dev F1_macro: {f1:.4f}\")\n",
        "            if f1 > (early_stop_entity.best_score or 0):\n",
        "                torch.save(entity_model.state_dict(), os.path.join(ACD_MODEL_DIR, 'best_model.pt'))\n",
        "                print(\"Saved best entity model\")\n",
        "            early_stop_entity.step(f1)\n",
        "            if early_stop_entity.should_stop:\n",
        "                print(\"Early stopping triggered (Entity)\")\n",
        "                if early_stop_polarity.should_stop:\n",
        "                  break\n",
        "\n",
        "        polarity_loss = train_one_epoch(polarity_model, polarity_train_loader, polarity_opt, polarity_sched, polarity_loss_fn)\n",
        "        print(f\"[Polarity] Epoch {epoch+1} | Train Loss: {polarity_loss:.4f}\")\n",
        "\n",
        "        if do_eval:\n",
        "            f1, preds, labels = evaluate_model(polarity_model, polarity_dev_loader)\n",
        "            print(f\"[Polarity] Dev F1_macro: {f1:.4f}\")\n",
        "            if f1 > (early_stop_polarity.best_score or 0):\n",
        "                torch.save(polarity_model.state_dict(), os.path.join(ASC_MODEL_DIR, 'best_model.pt'))\n",
        "                print(\"Saved best polarity model\")\n",
        "            early_stop_polarity.step(f1)\n",
        "            if early_stop_polarity.should_stop:\n",
        "                print(\"Early stopping triggered (Polarity)\")\n",
        "                if early_stop_entity.should_stop:\n",
        "                  break\n",
        "\n",
        "    print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPqQGkzAb0WG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749303524299,
          "user_tz": -540,
          "elapsed": 1139,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "603d4249-b11a-4e30-d9d2-2f74e444810b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 분할 완료: train=1098, dev=235, test=236\n"
          ]
        }
      ],
      "source": [
        "split_jsonl_file(\n",
        "    jsonl_path=converted_base_data_path,\n",
        "    output_dir=DATA_DIR,\n",
        "    train_ratio=0.7,\n",
        "    dev_ratio=0.15,\n",
        "    test_ratio=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7iPMzFjdWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c1c7df98504b49c6b723fa3c136f4099",
            "993503defc374363a44b76e9bb586a37",
            "886218f72263442c93467ee0d2d3797a",
            "1bcba85037c74bfd89ce1c200235dd73",
            "42c7c36317c34d7cbf2cdc99ff7a2098",
            "5522624c9545460f8d3015d925f46aeb",
            "4f281242b6464537b22c60782887de16",
            "4e0a8fd72fd14fe18545ff8d2fbebe9f",
            "b89e3fb6458b4f75a86ad947d6610405",
            "e22cf39fd5d54184a91b1735ce3aa9c2",
            "9ff54b52602f42d7b6abe1a9edfcbe7d",
            "f265f936fe904eb7b7410019aefb4b17",
            "c4d8179395ec4bd493eaf774a18c3516",
            "ee154f4e86d44b5f84f982a53386b374",
            "f8cc05b6f7df4d9c8d449ed9d2942796",
            "08199d6a65e14e189815fa3b6499c2a0",
            "0adc0951c581486587323b48377a900a",
            "c198fe713f35445e85aaa298afe85127",
            "0d36821a5a6d4f719ce3951716299b2c",
            "9cc7e3e71be14430920238f6a9aaa6a8",
            "1dd890f9430849ed8f1ac63e91169e11",
            "5b2b2d1c83314bdd9406b7b24ba9ecf6",
            "6a5072c69935455e9a64e34568676e82",
            "85bb0f05a38d448cb1114a43638732f5",
            "7b097b65a00f4930ad1e7e8296609fe3",
            "1eb89e8bae1d4516b8b51eb9b6113514",
            "b6ed259f4d1f4713ba904202e9f23a5c",
            "8ef361622dc84d73b44fbb5a21e20fc6",
            "c3b15bc88c4448d7ba5461999f5980d7",
            "7bdff560a5274bbc81c1f33fcdc3c0db",
            "c812c8d33eed4c5298aa7546163853b1",
            "10aa5d39b36240f8b0ba9624cc7191eb",
            "54ba7b4642234480ba364fd02800e552",
            "08592f8dc136474c80d2fe0260a45bfb",
            "7d9b1773683e4310875104c2230b4973",
            "8093ab2a49fa485884cdcab9183b2f0f",
            "f6831fee91004a4eb6db8d5216d72f42",
            "c0954984a8ef4053bf2d42b9b258b222",
            "5b130245c82447b5b0c12a4b335962d2",
            "2d04112c0cff48e6b38d25b85c87e831",
            "235f56feed4148b188baca49d56952fc",
            "932325b2f71f4dcfb3c1473c81563d69",
            "85c7e0c1c9e84da0bfed8f36ed032ce4",
            "da97d386349d4b77950ae129ff420d10",
            "2784be79eebb46e0b4f656cfd878d70e",
            "34a7efc256bf4f858aef65bc1bda469d",
            "9f4344807478425bafc6637df0f23ef4",
            "af8ad070884843a08bfe21ab3112ba74",
            "14ccec6943924c5bb7ebccef9dcc1b59",
            "f908212691c54bdcb929b3ece437096e",
            "f35f25c7e4fb4513937bf546ae83d8a3",
            "3adbbf61aea149359ae3925bc08073db",
            "dc4c1c51200445a98343751af684e78e",
            "157dd91a4e594fdaadeffb9c01ff84e3",
            "3c6ce9ba6a6e4ab29566f7e6b3910069",
            "48d18cb37fb04aa780b01d251b58ac13",
            "962b2dfde3224c19b2db631a04bf3077",
            "c6930d705df94edabdf88bfb8506c232",
            "b5916c6217244f38be499c57afcd8848",
            "968f170f5b494203b440e3786e6c4e8e",
            "7a96649271f248c3881a18f809de17b7",
            "13d1038f4e6f44d2b62a0905909a36c5",
            "a08b0de17a1a47a29c4eb9fab36ffd99",
            "2617b25f309944269c32500be36a2a76",
            "cc7dd87057624b98bf7e60ab48a3d01f",
            "8cde1ce5de5446f495489d5aa88dd4e4",
            "3a616c9ad2c8459983119b26a552fcbb",
            "9d6c4a709a384184876c340a7fe46754",
            "b9961820c0434a38b16c6bd9d13b9e6b",
            "68004db9d3984b9f94ac9c81415ee355",
            "e55a5b51be2b489f92bf7c190f24ce3c",
            "6e53845fa8ac4484a2f14f6cd2d662fc",
            "811a47613dc44d528943d11e51518487",
            "2cfd8da43aff4eafa104e3df6eadf70c",
            "37fc8ce852604b95a1854f1f7447807e",
            "138f7cf3b52e4216b4eef693ffe9fc96",
            "94099ac5e1664709b9847532da394a23",
            "2096348be73a4a9996d6368246f6111e",
            "af5fca936ef0425e8e71022f123d4f80",
            "7acf8f73e8744d8bbe03b3cf5fbb52e5",
            "7c600364b6cf403a83cfb16c02d3cfd7",
            "ecbae88c14e342479721945754c68604",
            "2f5aa7ef2f6c4ae591fe332ba9e7a10d",
            "3ed24abaad7247428b450a41a2b1346e",
            "0a0771067e1e4a7ea7bfd3eaddcde1f2",
            "b0b699ee584e47b9b81fe161af37987c",
            "68deeeab552b426a8667898b22801cbf",
            "1b846989ef424389b08c01cfd5a82103",
            "748dcd80ddad4180a47529d7139d4b88",
            "029de3f05dd54f95998e5a4ef1ed87c0",
            "28c23f5774694c80bc8b1b41733f506c",
            "5700fc8f901d424882dcb42d413b6615",
            "38f0b25d350a4c60a0a4718842747c5c",
            "1032915a197744d1886d9cff47971823",
            "933dcf6a8bb7486285911b44cb1d204f",
            "c5bcce334154470ba328486b45661773",
            "746b388299044b48be6c63ceab456ce4",
            "d0b6d711c1f94f61aaca4ae0939e8db0",
            "84caaf03b360482b8d1c774cd83dccb5",
            "cf2d728aaa3d420e8d13697c01d97029",
            "13d0a972764b428e8021eb53d66e7011",
            "8ff73fcd6f16446eba910764a0cd6017",
            "f83ae1a29e4f4cb4a84c80daa2eec092",
            "1c33a8d2b14f4f6a86a53480156a8899",
            "726c53d419ef4facb3bcfdddffd34135",
            "0526b7e734c64acdbe5413cee14dda50",
            "1d6f7da3d162436ca062b12414a5f45f",
            "131e91eba2bd41768a172833bdb367d0",
            "30d6e1dc264b4da180798db840b1b7bb",
            "e80de0524cf24f6f9f6766482da65218",
            "21131578036149dc8ef8c21037c42d2d",
            "2ffeba2f7e8449d096b471364808516d",
            "72d313f004a04f61b01dde54fe55eb0d",
            "4bbc1282e2514c81861c6171b364ca00",
            "53f767be7aea47519d0c887bc9a73319",
            "05aac3c7077a48339e48bd225acada97",
            "470d72b1a8224e9a820d3b3f6b6a6f3c",
            "be5f273182904c69ae2ab65eca90a866",
            "90d47e823c3e41d3884711ed026b85fc",
            "60295938558644c187bea2e167a2d6af",
            "b2f145ae0b4a4122b2a191d81d8cef0a"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749303969093,
          "user_tz": -540,
          "elapsed": 440444,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "5219122f-bb8f-4bd7-a2bb-ff1d012c4f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentiment_analysis START\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1c7df98504b49c6b723fa3c136f4099"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f265f936fe904eb7b7410019aefb4b17"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a5072c69935455e9a64e34568676e82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08592f8dc136474c80d2fe0260a45bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2784be79eebb46e0b4f656cfd878d70e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d18cb37fb04aa780b01d251b58ac13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a616c9ad2c8459983119b26a552fcbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Class Weights:\n",
            "  - False (class 0): weight = 1.3846\n",
            "  - True (class 1): weight = 3.6000\n",
            "Polarity Class Weights:\n",
            "  - positive (class 0): weight = 1.1885\n",
            "  - negative (class 1): weight = 9.1729\n",
            "  - neutral (class 2): weight = 20.1653\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2096348be73a4a9996d6368246f6111e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "748dcd80ddad4180a47529d7139d4b88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf2d728aaa3d420e8d13697c01d97029"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21131578036149dc8ef8c21037c42d2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Epoch 1 | Train Loss: 0.6890\n",
            "[Entity] Dev F1_macro: 0.5555\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 1 | Train Loss: 1.0818\n",
            "[Polarity] Dev F1_macro: 0.3333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:   5%|▌         | 1/20 [01:11<22:43, 71.75s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 2 | Train Loss: 0.6335\n",
            "[Entity] Dev F1_macro: 0.6972\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 2 | Train Loss: 1.0008\n",
            "[Polarity] Dev F1_macro: 0.4655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  10%|█         | 2/20 [01:55<16:39, 55.55s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 3 | Train Loss: 0.3629\n",
            "[Entity] Dev F1_macro: 0.9116\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 3 | Train Loss: 0.9059\n",
            "[Polarity] Dev F1_macro: 0.5240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  15%|█▌        | 3/20 [02:41<14:23, 50.79s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 4 | Train Loss: 0.2373\n",
            "[Entity] Dev F1_macro: 0.9302\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 4 | Train Loss: 0.8477\n",
            "[Polarity] Dev F1_macro: 0.5926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  20%|██        | 4/20 [03:25<12:50, 48.13s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 5 | Train Loss: 0.2549\n",
            "[Entity] Dev F1_macro: 0.9446\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 5 | Train Loss: 0.7669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  25%|██▌       | 5/20 [04:08<11:37, 46.49s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.5852\n",
            "[Entity] Epoch 6 | Train Loss: 0.3016\n",
            "[Entity] Dev F1_macro: 0.9427\n",
            "[Polarity] Epoch 6 | Train Loss: 0.7400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  30%|███       | 6/20 [04:50<10:28, 44.89s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.5542\n",
            "[Entity] Epoch 7 | Train Loss: 0.3337\n",
            "[Entity] Dev F1_macro: 0.9438\n",
            "[Polarity] Epoch 7 | Train Loss: 0.6634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  35%|███▌      | 7/20 [05:32<09:29, 43.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.5791\n",
            "[Entity] Epoch 8 | Train Loss: 0.2923\n",
            "[Entity] Dev F1_macro: 0.9384\n",
            "[Polarity] Epoch 8 | Train Loss: 0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch:  40%|████      | 8/20 [06:13<08:37, 43.09s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.5816\n",
            "Early stopping triggered (Polarity)\n",
            "[Entity] Epoch 9 | Train Loss: 0.2804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 8/20 [06:47<10:10, 50.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Dev F1_macro: 0.9430\n",
            "Early stopping triggered (Entity)\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = jsonlload(train_data_path)\n",
        "dev_data = jsonlload(dev_data_path)\n",
        "train_sentiment_analysis(train_data, dev_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLJM3T2jEse"
      },
      "source": [
        "# 모델 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqSiRaPjF-z"
      },
      "source": [
        "학습된 모델을 바탕으로 국어원 데이터 형태를 만드는 방법 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDbTFCdrQbyn"
      },
      "outputs": [],
      "source": [
        "def predict_from_korean_form(acd_tokenizer, asc_tokenizer, acd_best_model, asc_best_model, data, max_len, threshold):\n",
        "    acd_confidences_all = []\n",
        "    asc_confidences_all = []\n",
        "\n",
        "    acd_best_model.eval()\n",
        "    asc_best_model.eval()\n",
        "\n",
        "    acd_pad_token_id = acd_tokenizer.pad_token_id\n",
        "    asc_pad_token_id = asc_tokenizer.pad_token_id\n",
        "\n",
        "    for sentence in data:\n",
        "        form = sentence.get('sentence_form', '')\n",
        "        form = preprocessing(form)\n",
        "        sentence['annotation'] = []\n",
        "\n",
        "        if not isinstance(form, str) or not form.strip():\n",
        "            print(f\"Invalid sentence skipped: {form}\")\n",
        "            continue\n",
        "\n",
        "        for pair in entity_property_pair:\n",
        "            # ACD 수행\n",
        "            acd_encoded = acd_tokenizer(\n",
        "                form,\n",
        "                pair,\n",
        "                padding=False,\n",
        "                truncation=False,\n",
        "                return_tensors='pt',\n",
        "                add_special_tokens=True\n",
        "            )\n",
        "\n",
        "            acd_input_ids = acd_encoded['input_ids'][0].tolist()\n",
        "            acd_attention_mask = acd_encoded['attention_mask'][0].tolist()\n",
        "            acd_input_ids, acd_attention_mask = truncate_left(acd_input_ids, acd_attention_mask, max_len, acd_pad_token_id)\n",
        "\n",
        "            acd_input_ids = torch.tensor([acd_input_ids]).to(device)\n",
        "            acd_attention_mask = torch.tensor([acd_attention_mask]).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                _, acd_logits = acd_best_model(acd_input_ids, acd_attention_mask)\n",
        "\n",
        "            acd_probs = torch.softmax(acd_logits, dim=-1)\n",
        "            acd_confidence, acd_pred = torch.max(acd_probs, dim=-1)\n",
        "            acd_pred = acd_pred.item()\n",
        "            acd_confidence = acd_confidence.item()\n",
        "            acd_confidences_all.append(acd_confidence)\n",
        "\n",
        "            if tf_id_to_name[acd_pred] == 'True' and acd_confidence >= threshold:\n",
        "                # ASC 수행\n",
        "                asc_encoded = asc_tokenizer(\n",
        "                    form,\n",
        "                    pair,\n",
        "                    padding=False,\n",
        "                    truncation=False,\n",
        "                    return_tensors='pt',\n",
        "                    add_special_tokens=True\n",
        "                )\n",
        "                asc_input_ids = asc_encoded['input_ids'][0].tolist()\n",
        "                asc_attention_mask = asc_encoded['attention_mask'][0].tolist()\n",
        "                asc_input_ids, asc_attention_mask = truncate_left(asc_input_ids, asc_attention_mask, max_len, asc_pad_token_id)\n",
        "\n",
        "                asc_input_ids = torch.tensor([asc_input_ids]).to(device)\n",
        "                asc_attention_mask = torch.tensor([asc_attention_mask]).to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    _, asc_logits = asc_best_model(asc_input_ids, asc_attention_mask)\n",
        "\n",
        "                asc_probs = torch.softmax(asc_logits, dim=-1)\n",
        "                asc_confidence, asc_pred = torch.max(asc_probs, dim=-1)\n",
        "                asc_pred = asc_pred.item()\n",
        "                asc_confidence = asc_confidence.item()\n",
        "                asc_confidences_all.append(asc_confidence)\n",
        "\n",
        "                if 0 <= asc_pred < len(polarity_id_to_name):\n",
        "                    polarity = polarity_id_to_name[asc_pred]\n",
        "                else:\n",
        "                    polarity = \"UNKNOWN\"\n",
        "\n",
        "                sentence['annotation'].append([\n",
        "                    pair,\n",
        "                    [None, 0, 0],\n",
        "                    polarity\n",
        "                ])\n",
        "\n",
        "        if not sentence['annotation']:\n",
        "            sentence['annotation'] = [[\"없음\", [None, 0, 0], None]]\n",
        "\n",
        "    if acd_confidences_all:\n",
        "        print(\"Confidence 값 분포 (ACD 단계):\")\n",
        "        print(f\"  - max: {max(acd_confidences_all):.4f}\")\n",
        "        print(f\"  - min: {min(acd_confidences_all):.4f}\")\n",
        "        print(f\"  - mean: {np.mean(acd_confidences_all):.4f}\")\n",
        "        print(f\"  - median: {np.median(acd_confidences_all):.4f}\")\n",
        "\n",
        "    if asc_confidences_all:\n",
        "        print(\"\\nConfidence 값 분포 (ASC 단계):\")\n",
        "        print(f\"  - max: {max(asc_confidences_all):.4f}\")\n",
        "        print(f\"  - min: {min(asc_confidences_all):.4f}\")\n",
        "        print(f\"  - mean: {np.mean(asc_confidences_all):.4f}\")\n",
        "        print(f\"  - median: {np.median(asc_confidences_all):.4f}\")\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8V29G0jONu"
      },
      "source": [
        "F1 score 계산 - acd 성능 및 전체 성능 (absa) 에 대한 F1 score 따로 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrZfT2gDQb2o"
      },
      "outputs": [],
      "source": [
        "def evaluation_f1(true_data, pred_data):\n",
        "    acd_eval = {'tp': 0, 'fp': 0, 'fn': 0}\n",
        "    absa_eval = {'tp': 0, 'fp': 0, 'fn': 0}\n",
        "\n",
        "    if len(true_data) != len(pred_data):\n",
        "        print(f\"Warning: Length mismatch (true={len(true_data)}, pred={len(pred_data)})\")\n",
        "\n",
        "    for true_item, pred_item in zip(true_data, pred_data):\n",
        "        true_annos = true_item.get('annotation', [])\n",
        "        pred_annos = pred_item.get('annotation', [])\n",
        "\n",
        "        true_acd_set = set()\n",
        "        true_absa_set = set()\n",
        "        for anno in true_annos:\n",
        "            if len(anno) == 3 and anno[0] != '없음':\n",
        "                true_acd_set.add(anno[0])\n",
        "                true_absa_set.add((anno[0], anno[2]))\n",
        "\n",
        "        pred_acd_set = set()\n",
        "        pred_absa_set = set()\n",
        "        for anno in pred_annos:\n",
        "            if len(anno) == 3 and anno[0] != '없음':\n",
        "                pred_acd_set.add(anno[0])\n",
        "                pred_absa_set.add((anno[0], anno[2]))\n",
        "\n",
        "        acd_eval['tp'] += len(true_acd_set & pred_acd_set)\n",
        "        acd_eval['fp'] += len(pred_acd_set - true_acd_set)\n",
        "        acd_eval['fn'] += len(true_acd_set - pred_acd_set)\n",
        "\n",
        "        absa_eval['tp'] += len(true_absa_set & pred_absa_set)\n",
        "        absa_eval['fp'] += len(pred_absa_set - true_absa_set)\n",
        "        absa_eval['fn'] += len(true_absa_set - pred_absa_set)\n",
        "\n",
        "    def calc_f1(tp, fp, fn):\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "        return {\n",
        "            'Precision': round(precision, 4),\n",
        "            'Recall': round(recall, 4),\n",
        "            'F1': round(f1, 4)\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        'ACD result': calc_f1(**acd_eval),\n",
        "        'entire ABSA result': calc_f1(**absa_eval)\n",
        "    }\n",
        "\n",
        "def evaluation_per_aspect(true_data, pred_data):\n",
        "    aspect_labels = list(set(\n",
        "        anno[0]\n",
        "        for sample in true_data\n",
        "        for anno in sample.get(\"annotation\", [])\n",
        "        if len(anno) == 3\n",
        "    ))\n",
        "    if '없음' not in aspect_labels:\n",
        "        aspect_labels.append('없음')\n",
        "\n",
        "    aspect_metrics = {}\n",
        "\n",
        "    for aspect in sorted(aspect_labels):\n",
        "        y_true_acd = []\n",
        "        y_pred_acd = []\n",
        "\n",
        "        tp = fp = fn = 0\n",
        "\n",
        "        for true_item, pred_item in zip(true_data, pred_data):\n",
        "            true_annos = [anno for anno in true_item.get(\"annotation\", []) if len(anno) == 3]\n",
        "            pred_annos = [anno for anno in pred_item.get(\"annotation\", []) if len(anno) == 3]\n",
        "\n",
        "            true_aspects_set = set(anno[0] for anno in true_annos)\n",
        "            pred_aspects_set = set(anno[0] for anno in pred_annos)\n",
        "\n",
        "            if aspect == '없음':\n",
        "                y_true_acd.append(1 if len(true_aspects_set - {'없음'}) == 0 else 0)\n",
        "                y_pred_acd.append(1 if len(pred_aspects_set - {'없음'}) == 0 else 0)\n",
        "            else:\n",
        "                y_true_acd.append(1 if aspect in true_aspects_set else 0)\n",
        "                y_pred_acd.append(1 if aspect in pred_aspects_set else 0)\n",
        "\n",
        "            if aspect == '없음':\n",
        "                y_true_absa_set = set((anno[0], anno[2]) for anno in true_annos if anno[0] != '없음')\n",
        "                y_pred_absa_set = set((anno[0], anno[2]) for anno in pred_annos if anno[0] != '없음')\n",
        "\n",
        "                y_true_none = len(true_absa_set) == 0\n",
        "                y_pred_none = len(pred_absa_set) == 0\n",
        "\n",
        "                if y_true_none and y_pred_none:\n",
        "                    tp += 1\n",
        "                elif y_pred_none and not y_true_none:\n",
        "                    fn += 1\n",
        "                elif y_true_none and not y_pred_none:\n",
        "                    fp += 1\n",
        "                else:\n",
        "                    pass\n",
        "            else:\n",
        "                true_absa_set = set((anno[0], anno[2]) for anno in true_annos if anno[0] == aspect)\n",
        "                pred_absa_set = set((anno[0], anno[2]) for anno in pred_annos if anno[0] == aspect)\n",
        "\n",
        "                tp += len(true_absa_set & pred_absa_set)\n",
        "                fp += len(pred_absa_set - true_absa_set)\n",
        "                fn += len(true_absa_set - pred_absa_set)\n",
        "\n",
        "        acd_precision = precision_score(y_true_acd, y_pred_acd, zero_division=0)\n",
        "        acd_recall = recall_score(y_true_acd, y_pred_acd, zero_division=0)\n",
        "        acd_f1 = f1_score(y_true_acd, y_pred_acd, zero_division=0)\n",
        "\n",
        "        absa_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        absa_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        absa_f1 = (\n",
        "            2 * absa_precision * absa_recall / (absa_precision + absa_recall)\n",
        "            if (absa_precision + absa_recall) > 0 else 0\n",
        "        )\n",
        "\n",
        "        aspect_metrics[aspect] = {\n",
        "            'ACD_Precision': round(acd_precision, 4),\n",
        "            'ACD_Recall': round(acd_recall, 4),\n",
        "            'ACD_F1': round(acd_f1, 4),\n",
        "            'ABSA_Precision': round(absa_precision, 4),\n",
        "            'ABSA_Recall': round(absa_recall, 4),\n",
        "            'ABSA_F1': round(absa_f1, 4),\n",
        "            'Support': sum(y_true_acd)\n",
        "        }\n",
        "\n",
        "    return aspect_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpQwoVahjZoV"
      },
      "source": [
        "테스트 데이터에 대한 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Npy40TZoQlmS"
      },
      "outputs": [],
      "source": [
        "def load_model(model_class, path, model_name, label_size, tokenizer_len):\n",
        "    model = model_class(model_name, label_size, tokenizer_len)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def pretty_print_result(result_dict, aspect_dict=None):\n",
        "    print(\"\\nF1 Evaluation Result:\")\n",
        "    for name, metrics in result_dict.items():\n",
        "        print(f\"\\n▶ {name}\")\n",
        "        for k, v in metrics.items():\n",
        "            print(f\"   {k}: {v:.4f}\")\n",
        "\n",
        "    if aspect_dict:\n",
        "        print(\"\\nPer-Aspect Performance:\")\n",
        "        for aspect, metrics in aspect_dict.items():\n",
        "            print(f\"\\n - {aspect}\")\n",
        "            for k, v in metrics.items():\n",
        "                print(f\"   {k}: {v}\")\n",
        "\n",
        "def test_sentiment_analysis(test_data, save_path=None):\n",
        "    print(\"Starting Sentiment Analysis Test...\")\n",
        "\n",
        "    try:\n",
        "        acd_tokenizer = AutoTokenizer.from_pretrained(acd_base_model)\n",
        "        acd_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "        asc_tokenizer = AutoTokenizer.from_pretrained(asc_base_model)\n",
        "        asc_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    except Exception as e:\n",
        "        print(f\"Tokenizer load error: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        test_data = ensure_annotation(test_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load test data: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        entity_test_data, _, _, _ = get_dataset(test_data, acd_tokenizer, max_len)\n",
        "        _, polarity_test_data, _, _ = get_dataset(test_data, asc_tokenizer, max_len)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to preprocess test data: {e}\")\n",
        "        return\n",
        "\n",
        "    entity_test_loader = DataLoader(entity_test_data, shuffle=False, batch_size=batch_size)\n",
        "    polarity_test_loader = DataLoader(polarity_test_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    try:\n",
        "        acd_best_model = load_model(ABSA_Model, acd_best_model_path, acd_base_model, len(tf_id_to_name), len(acd_tokenizer))\n",
        "        asc_best_model = load_model(ABSA_Model, asc_best_model_path, asc_base_model, len(polarity_id_to_name), len(asc_tokenizer))\n",
        "    except Exception as e:\n",
        "        print(f\"Model load error: {e}\")\n",
        "        return\n",
        "\n",
        "    acd_best_model.eval()\n",
        "    asc_best_model.eval()\n",
        "\n",
        "    acd_total_loss, acd_batches = 0.0, 0\n",
        "    asc_total_loss, asc_batches = 0.0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, labels in entity_test_loader:\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "            loss, _ = acd_best_model(input_ids, attention_mask, labels)\n",
        "            acd_total_loss += loss.item()\n",
        "            acd_batches += 1\n",
        "\n",
        "        for input_ids, attention_mask, labels in polarity_test_loader:\n",
        "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "            loss, _ = asc_best_model(input_ids, attention_mask, labels)\n",
        "            asc_total_loss += loss.item()\n",
        "            asc_batches += 1\n",
        "\n",
        "    pred_data = predict_from_korean_form(acd_tokenizer, asc_tokenizer, acd_best_model, asc_best_model, copy.deepcopy(test_data), max_len, threshold)\n",
        "\n",
        "    result = evaluation_f1(test_data, pred_data)\n",
        "    aspect_result = evaluation_per_aspect(test_data, pred_data)\n",
        "\n",
        "    pretty_print_result(result, aspect_result)\n",
        "\n",
        "    print(\"\\nAverage Loss:\")\n",
        "    if acd_batches > 0:\n",
        "        print(f\" - ACD Loss: {acd_total_loss / acd_batches:.4f}\")\n",
        "    if asc_batches > 0:\n",
        "        print(f\" - ASC Loss: {asc_total_loss / asc_batches:.4f}\")\n",
        "\n",
        "    save_path = pred_result_DIR\n",
        "    if save_path:\n",
        "        try:\n",
        "            jsondump(pred_data, 'pred_data.jsonl')\n",
        "            print(f\"Saved predictions to {save_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save predictions: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 34569,
          "status": "ok",
          "timestamp": 1749305307544,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          },
          "user_tz": -540
        },
        "id": "K1QaMuWCc5jV",
        "outputId": "8188b78d-fd03-45a9-9222-2e44dd997fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sentiment Analysis Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence 값 분포 (ACD 단계):\n",
            "  - max: 0.9999\n",
            "  - min: 0.5351\n",
            "  - mean: 0.9952\n",
            "  - median: 0.9997\n",
            "\n",
            "Confidence 값 분포 (ASC 단계):\n",
            "  - max: 0.9671\n",
            "  - min: 0.3570\n",
            "  - mean: 0.7467\n",
            "  - median: 0.8195\n",
            "\n",
            "F1 Evaluation Result:\n",
            "\n",
            "▶ ACD result\n",
            "   Precision: 0.9105\n",
            "   Recall: 0.9124\n",
            "   F1: 0.9114\n",
            "\n",
            "▶ entire ABSA result\n",
            "   Precision: 0.7078\n",
            "   Recall: 0.7036\n",
            "   F1: 0.7056\n",
            "\n",
            "Per-Aspect Performance:\n",
            "\n",
            " - 가격\n",
            "   ACD_Precision: 0.92\n",
            "   ACD_Recall: 0.9583\n",
            "   ACD_F1: 0.9388\n",
            "   ABSA_Precision: 0.64\n",
            "   ABSA_Recall: 0.6667\n",
            "   ABSA_F1: 0.6531\n",
            "   Support: 24\n",
            "\n",
            " - 거품\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9703\n",
            "   ACD_F1: 0.9849\n",
            "   ABSA_Precision: 0.7551\n",
            "   ABSA_Recall: 0.7327\n",
            "   ABSA_F1: 0.7437\n",
            "   Support: 101\n",
            "\n",
            " - 머릿결\n",
            "   ACD_Precision: 0.75\n",
            "   ACD_Recall: 0.9808\n",
            "   ACD_F1: 0.85\n",
            "   ABSA_Precision: 0.5294\n",
            "   ABSA_Recall: 0.6923\n",
            "   ABSA_F1: 0.6\n",
            "   Support: 52\n",
            "\n",
            " - 세정\n",
            "   ACD_Precision: 0.9035\n",
            "   ACD_Recall: 0.8655\n",
            "   ACD_F1: 0.8841\n",
            "   ABSA_Precision: 0.7632\n",
            "   ABSA_Recall: 0.7311\n",
            "   ABSA_F1: 0.7468\n",
            "   Support: 119\n",
            "\n",
            " - 없음\n",
            "   ACD_Precision: 0.0\n",
            "   ACD_Recall: 0.0\n",
            "   ACD_F1: 0.0\n",
            "   ABSA_Precision: 0\n",
            "   ABSA_Recall: 0\n",
            "   ABSA_F1: 0\n",
            "   Support: 0\n",
            "\n",
            " - 자극\n",
            "   ACD_Precision: 0.8684\n",
            "   ACD_Recall: 0.825\n",
            "   ACD_F1: 0.8462\n",
            "   ABSA_Precision: 0.6579\n",
            "   ABSA_Recall: 0.6098\n",
            "   ABSA_F1: 0.6329\n",
            "   Support: 40\n",
            "\n",
            " - 쿨링\n",
            "   ACD_Precision: 0.8\n",
            "   ACD_Recall: 0.8571\n",
            "   ACD_F1: 0.8276\n",
            "   ABSA_Precision: 0.7333\n",
            "   ABSA_Recall: 0.7857\n",
            "   ABSA_F1: 0.7586\n",
            "   Support: 14\n",
            "\n",
            " - 탈모\n",
            "   ACD_Precision: 0.8235\n",
            "   ACD_Recall: 0.5833\n",
            "   ACD_F1: 0.6829\n",
            "   ABSA_Precision: 0.7059\n",
            "   ABSA_Recall: 0.5\n",
            "   ABSA_F1: 0.5854\n",
            "   Support: 24\n",
            "\n",
            " - 향\n",
            "   ACD_Precision: 0.9688\n",
            "   ACD_Recall: 0.9688\n",
            "   ACD_F1: 0.9688\n",
            "   ABSA_Precision: 0.7422\n",
            "   ABSA_Recall: 0.7252\n",
            "   ABSA_F1: 0.7336\n",
            "   Support: 128\n",
            "\n",
            "Average Loss:\n",
            " - ACD Loss: 0.6290\n",
            " - ASC Loss: 0.7257\n",
            "Saved predictions to /content/drive/MyDrive/ABSA/pred_result\n"
          ]
        }
      ],
      "source": [
        "test_data = jsonlload(test_data_path)\n",
        "test_sentiment_analysis(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQKFoCIa07Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 증강 데이터 사용"
      ],
      "metadata": {
        "id": "GdjyrvM0hWDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_all_data_path = os.path.join(DATA_DIR, 'aug_all_withko_nn.jsonl')\n",
        "converted_aug_all_data_path = os.path.join(DATA_DIR, 'converted_aug_all_withko_nn.jsonl')\n",
        "\n",
        "aug_data = jsonlload(aug_all_data_path)\n",
        "converted_aug_data = convert_to_absa_format(aug_data)\n",
        "jsonldump(converted_aug_data, converted_aug_all_data_path)\n",
        "jsonlload(converted_aug_all_data_path)"
      ],
      "metadata": {
        "id": "AzoAuwnch8Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_jsonl_file_train_dev_only(\n",
        "    jsonl_path=converted_aug_all_data_path,\n",
        "    output_dir=DATA_DIR,\n",
        "    train_ratio=0.9,\n",
        "    dev_ratio=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8QrCfLhhZGF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749305401443,
          "user_tz": -540,
          "elapsed": 80,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "99b0e2b7-8768-475f-d9fb-cde62fcbbf6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 분할 완료: train=2367, dev=264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = jsonlload(train_data_path)\n",
        "dev_data = jsonlload(dev_data_path)\n",
        "train_sentiment_analysis(train_data, dev_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z34AZbNBiumB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749307845488,
          "user_tz": -540,
          "elapsed": 2442356,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "33a86e2b-0413-48e4-8309-a8eea87d59fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentiment_analysis START\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Class Weights:\n",
            "  - False (class 0): weight = 1.2977\n",
            "  - True (class 1): weight = 4.3593\n",
            "Polarity Class Weights:\n",
            "  - positive (class 0): weight = 1.6535\n",
            "  - negative (class 1): weight = 3.8054\n",
            "  - neutral (class 2): weight = 7.5513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Epoch 1 | Train Loss: 0.5967\n",
            "[Entity] Dev F1_macro: 0.8385\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 1 | Train Loss: 0.8240\n",
            "[Polarity] Dev F1_macro: 0.6154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   3%|▎         | 1/30 [01:30<43:42, 90.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 2 | Train Loss: 0.3177\n",
            "[Entity] Dev F1_macro: 0.8771\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 2 | Train Loss: 0.6805\n",
            "[Polarity] Dev F1_macro: 0.7110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   7%|▋         | 2/30 [03:01<42:20, 90.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 3 | Train Loss: 0.2815\n",
            "[Entity] Dev F1_macro: 0.8827\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 3 | Train Loss: 0.6076\n",
            "[Polarity] Dev F1_macro: 0.7236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 3/30 [04:32<40:52, 90.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 4 | Train Loss: 0.2734\n",
            "[Entity] Dev F1_macro: 0.8962\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 4 | Train Loss: 0.5730\n",
            "[Polarity] Dev F1_macro: 0.7390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 4/30 [06:03<39:22, 90.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 5 | Train Loss: 0.2923\n",
            "[Entity] Dev F1_macro: 0.9009\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 5 | Train Loss: 0.5138\n",
            "[Polarity] Dev F1_macro: 0.7454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  17%|█▋        | 5/30 [07:34<37:53, 90.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 6 | Train Loss: 0.3673\n",
            "[Entity] Dev F1_macro: 0.9109\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 6 | Train Loss: 0.4807\n",
            "[Polarity] Dev F1_macro: 0.7721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 6/30 [09:05<36:24, 91.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 7 | Train Loss: 0.4547\n",
            "[Entity] Dev F1_macro: 0.9133\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 7 | Train Loss: 0.4112\n",
            "[Polarity] Dev F1_macro: 0.7952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  23%|██▎       | 7/30 [10:36<34:57, 91.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 8 | Train Loss: 0.4789\n",
            "[Entity] Dev F1_macro: 0.9160\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 8 | Train Loss: 0.3675\n",
            "[Polarity] Dev F1_macro: 0.7954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 8/30 [12:08<33:30, 91.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 9 | Train Loss: 0.4099\n",
            "[Entity] Dev F1_macro: 0.9143\n",
            "[Polarity] Epoch 9 | Train Loss: 0.3368\n",
            "[Polarity] Dev F1_macro: 0.8225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 9/30 [13:33<31:18, 89.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 10 | Train Loss: 0.3606\n",
            "[Entity] Dev F1_macro: 0.9223\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 10 | Train Loss: 0.2604\n",
            "[Polarity] Dev F1_macro: 0.8250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 10/30 [15:05<29:58, 89.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 11 | Train Loss: 0.3514\n",
            "[Entity] Dev F1_macro: 0.9225\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 11 | Train Loss: 0.2350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  37%|███▋      | 11/30 [16:30<28:01, 88.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8126\n",
            "[Entity] Epoch 12 | Train Loss: 0.3508\n",
            "[Entity] Dev F1_macro: 0.9216\n",
            "[Polarity] Epoch 12 | Train Loss: 0.2145\n",
            "[Polarity] Dev F1_macro: 0.8479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 12/30 [17:54<26:11, 87.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 13 | Train Loss: 0.3395\n",
            "[Entity] Dev F1_macro: 0.9205\n",
            "[Polarity] Epoch 13 | Train Loss: 0.2091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  43%|████▎     | 13/30 [19:18<24:25, 86.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8326\n",
            "[Entity] Epoch 14 | Train Loss: 0.3058\n",
            "[Entity] Dev F1_macro: 0.9211\n",
            "[Polarity] Epoch 14 | Train Loss: 0.1960\n",
            "[Polarity] Dev F1_macro: 0.8639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 14/30 [20:42<22:50, 85.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 15 | Train Loss: 0.2659\n",
            "[Entity] Dev F1_macro: 0.9162\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 15 | Train Loss: 0.1950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 15/30 [22:06<21:15, 85.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8620\n",
            "[Entity] Epoch 16 | Train Loss: 0.2518\n",
            "[Entity] Dev F1_macro: 0.9287\n",
            "Saved best entity model\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 16 | Train Loss: 0.1654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 16/30 [23:31<19:48, 84.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8622\n",
            "[Entity] Epoch 17 | Train Loss: 0.2547\n",
            "[Entity] Dev F1_macro: 0.9231\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 17 | Train Loss: 0.1577\n",
            "[Polarity] Dev F1_macro: 0.8639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  57%|█████▋    | 17/30 [24:55<18:22, 84.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 18 | Train Loss: 0.2537\n",
            "[Entity] Dev F1_macro: 0.9243\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 18 | Train Loss: 0.2022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 18/30 [26:19<16:54, 84.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8602\n",
            "[Entity] Epoch 19 | Train Loss: 0.2256\n",
            "[Entity] Dev F1_macro: 0.9255\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 19 | Train Loss: 0.1803\n",
            "[Polarity] Dev F1_macro: 0.8663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  63%|██████▎   | 19/30 [27:44<15:29, 84.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 20 | Train Loss: 0.2159\n",
            "[Entity] Dev F1_macro: 0.9279\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 20 | Train Loss: 0.2034\n",
            "[Polarity] Dev F1_macro: 0.8721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 20/30 [29:09<14:07, 84.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 21 | Train Loss: 0.2254\n",
            "[Entity] Dev F1_macro: 0.9304\n",
            "Saved best entity model\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 21 | Train Loss: 0.2057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 21/30 [30:34<12:43, 84.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8713\n",
            "[Entity] Epoch 22 | Train Loss: 0.2145\n",
            "[Entity] Dev F1_macro: 0.9266\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 22 | Train Loss: 0.2119\n",
            "[Polarity] Dev F1_macro: 0.8773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 22/30 [31:59<11:18, 84.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 23 | Train Loss: 0.2018\n",
            "[Entity] Dev F1_macro: 0.9296\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 23 | Train Loss: 0.1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  77%|███████▋  | 23/30 [33:23<09:51, 84.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8725\n",
            "[Entity] Epoch 24 | Train Loss: 0.2187\n",
            "[Entity] Dev F1_macro: 0.9287\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 24 | Train Loss: 0.1931\n",
            "[Polarity] Dev F1_macro: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 24/30 [34:47<08:27, 84.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 25 | Train Loss: 0.2070\n",
            "[Entity] Dev F1_macro: 0.9282\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 25 | Train Loss: 0.1725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [36:11<07:01, 84.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8777\n",
            "[Entity] Epoch 26 | Train Loss: 0.1862\n",
            "[Entity] Dev F1_macro: 0.9307\n",
            "Saved best entity model\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 26 | Train Loss: 0.1681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 26/30 [37:36<05:38, 84.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8777\n",
            "[Entity] Epoch 27 | Train Loss: 0.1955\n",
            "[Entity] Dev F1_macro: 0.9264\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 27 | Train Loss: 0.2020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [39:00<04:13, 84.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8764\n",
            "[Entity] Epoch 28 | Train Loss: 0.1901\n",
            "[Entity] Dev F1_macro: 0.9300\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 28 | Train Loss: 0.1719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [40:24<04:29, 89.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8662\n",
            "Early stopping triggered (Polarity)\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = jsonlload(test_data_path)\n",
        "test_sentiment_analysis(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP4klbHnizTb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749307880698,
          "user_tz": -540,
          "elapsed": 35159,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "84b1da55-3076-43f6-dfe8-d42494e9456a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sentiment Analysis Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence 값 분포 (ACD 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.7700\n",
            "  - mean: 0.9999\n",
            "  - median: 1.0000\n",
            "\n",
            "Confidence 값 분포 (ASC 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.5777\n",
            "  - mean: 0.9967\n",
            "  - median: 1.0000\n",
            "\n",
            "F1 Evaluation Result:\n",
            "\n",
            "▶ ACD result\n",
            "   Precision: 0.9722\n",
            "   Recall: 0.9741\n",
            "   F1: 0.9731\n",
            "\n",
            "▶ entire ABSA result\n",
            "   Precision: 0.9443\n",
            "   Recall: 0.9387\n",
            "   F1: 0.9415\n",
            "\n",
            "Per-Aspect Performance:\n",
            "\n",
            " - 가격\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9583\n",
            "   ACD_F1: 0.9787\n",
            "   ABSA_Precision: 0.9565\n",
            "   ABSA_Recall: 0.9167\n",
            "   ABSA_F1: 0.9362\n",
            "   Support: 24\n",
            "\n",
            " - 거품\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9901\n",
            "   ACD_F1: 0.995\n",
            "   ABSA_Precision: 0.98\n",
            "   ABSA_Recall: 0.9703\n",
            "   ABSA_F1: 0.9751\n",
            "   Support: 101\n",
            "\n",
            " - 머릿결\n",
            "   ACD_Precision: 0.963\n",
            "   ACD_Recall: 1.0\n",
            "   ACD_F1: 0.9811\n",
            "   ABSA_Precision: 0.9074\n",
            "   ABSA_Recall: 0.9423\n",
            "   ABSA_F1: 0.9245\n",
            "   Support: 52\n",
            "\n",
            " - 세정\n",
            "   ACD_Precision: 0.9746\n",
            "   ACD_Recall: 0.9664\n",
            "   ACD_F1: 0.9705\n",
            "   ABSA_Precision: 0.9661\n",
            "   ABSA_Recall: 0.958\n",
            "   ABSA_F1: 0.962\n",
            "   Support: 119\n",
            "\n",
            " - 없음\n",
            "   ACD_Precision: 0.0\n",
            "   ACD_Recall: 0.0\n",
            "   ACD_F1: 0.0\n",
            "   ABSA_Precision: 0\n",
            "   ABSA_Recall: 0\n",
            "   ABSA_F1: 0\n",
            "   Support: 0\n",
            "\n",
            " - 자극\n",
            "   ACD_Precision: 0.9268\n",
            "   ACD_Recall: 0.95\n",
            "   ACD_F1: 0.9383\n",
            "   ABSA_Precision: 0.9024\n",
            "   ABSA_Recall: 0.9024\n",
            "   ABSA_F1: 0.9024\n",
            "   Support: 40\n",
            "\n",
            " - 쿨링\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 1.0\n",
            "   ACD_F1: 1.0\n",
            "   ABSA_Precision: 1.0\n",
            "   ABSA_Recall: 1.0\n",
            "   ABSA_F1: 1.0\n",
            "   Support: 14\n",
            "\n",
            " - 탈모\n",
            "   ACD_Precision: 0.9091\n",
            "   ACD_Recall: 0.8333\n",
            "   ACD_F1: 0.8696\n",
            "   ABSA_Precision: 0.8636\n",
            "   ABSA_Recall: 0.7917\n",
            "   ABSA_F1: 0.8261\n",
            "   Support: 24\n",
            "\n",
            " - 향\n",
            "   ACD_Precision: 0.9695\n",
            "   ACD_Recall: 0.9922\n",
            "   ACD_F1: 0.9807\n",
            "   ABSA_Precision: 0.9313\n",
            "   ABSA_Recall: 0.9313\n",
            "   ABSA_F1: 0.9313\n",
            "   Support: 128\n",
            "\n",
            "Average Loss:\n",
            " - ACD Loss: 0.8687\n",
            " - ASC Loss: 1.0650\n",
            "Saved predictions to /content/drive/MyDrive/ABSA/pred_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZD8VQVOsi30s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StratifiedKFold 적용"
      ],
      "metadata": {
        "id": "VasFqGjeUXHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evMGFCGCtHcz",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749254710026,
          "user_tz": -540,
          "elapsed": 6044,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "160d84b0-03da-471f-cc8f-01c9a22777c2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ],
      "metadata": {
        "id": "Xb-mRE2JtfDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seedNum, device='cpu'):\n",
        "    torch.manual_seed(seedNum)\n",
        "    np.random.seed(seedNum)\n",
        "    random.seed(seedNum)\n",
        "    if device == 'cuda' and torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seedNum)\n",
        "        torch.cuda.manual_seed_all(seedNum)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def custom_stratified_KFold(file_list, n_splits, which_k):\n",
        "    data = jsonlload(file_list)\n",
        "    labels = []\n",
        "\n",
        "    for d in data:\n",
        "        annotation = d.get(\"annotation\", [])\n",
        "        if not annotation:\n",
        "            labels.append(0)\n",
        "            continue\n",
        "        max_idx = max(entity_property_pair.index(anno[0]) for anno in annotation if anno[0] in entity_property_pair)\n",
        "        labels.append(max_idx)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
        "\n",
        "    for n_iter, (train_idx, test_idx) in enumerate(skf.split(data, labels), 1):\n",
        "        if n_iter == which_k:\n",
        "            print(f'CustomStratifiedKFold - {n_iter}/{n_splits}')\n",
        "            train_data = [data[i] for i in train_idx]\n",
        "            test_data = [data[i] for i in test_idx]\n",
        "\n",
        "            save_path = os.path.join(DATA_DIR, f\"{n_iter}Fold.jsonl\")\n",
        "            jsondump(test_data, save_path)\n",
        "\n",
        "            return train_data, test_data\n",
        "\n",
        "set_seed(1, device)\n",
        "\n",
        "# input_file_list = [\"train.jsonl\", \"dev.jsonl\", \"temp_aug.jsonl\"]\n",
        "input_file_list = [\"train.jsonl\", \"dev.jsonl\"]"
      ],
      "metadata": {
        "id": "OepDOeYANXqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, dev_data = custom_stratified_KFold(input_file_list, 3, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIlIMMUYazci",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749308039821,
          "user_tz": -540,
          "elapsed": 283,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "df6d80f4-f082-4fc5-ecb0-c25bccb2050e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomStratifiedKFold - 1/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentiment_analysis(train_data, dev_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhoJRJEllDhB",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749310419968,
          "user_tz": -540,
          "elapsed": 2376079,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "f2e804f7-f90a-45e9-d5c8-3fb71001a57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentiment_analysis START\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Class Weights:\n",
            "  - False (class 0): weight = 1.3015\n",
            "  - True (class 1): weight = 4.3166\n",
            "Polarity Class Weights:\n",
            "  - positive (class 0): weight = 1.6432\n",
            "  - negative (class 1): weight = 3.9215\n",
            "  - neutral (class 2): weight = 7.3296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Epoch 1 | Train Loss: 0.5538\n",
            "[Entity] Dev F1_macro: 0.8450\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 1 | Train Loss: 0.8188\n",
            "[Polarity] Dev F1_macro: 0.6428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   3%|▎         | 1/30 [01:14<36:13, 74.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 2 | Train Loss: 0.3282\n",
            "[Entity] Dev F1_macro: 0.8642\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 2 | Train Loss: 0.6707\n",
            "[Polarity] Dev F1_macro: 0.6861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   7%|▋         | 2/30 [02:37<36:56, 79.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 3 | Train Loss: 0.2954\n",
            "[Entity] Dev F1_macro: 0.8720\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 3 | Train Loss: 0.6112\n",
            "[Polarity] Dev F1_macro: 0.7061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 3/30 [03:59<36:22, 80.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 4 | Train Loss: 0.2761\n",
            "[Entity] Dev F1_macro: 0.8753\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 4 | Train Loss: 0.5459\n",
            "[Polarity] Dev F1_macro: 0.7170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 4/30 [05:22<35:21, 81.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 5 | Train Loss: 0.2657\n",
            "[Entity] Dev F1_macro: 0.8858\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 5 | Train Loss: 0.5136\n",
            "[Polarity] Dev F1_macro: 0.7225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  17%|█▋        | 5/30 [06:45<34:08, 81.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 6 | Train Loss: 0.2534\n",
            "[Entity] Dev F1_macro: 0.8881\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 6 | Train Loss: 0.4641\n",
            "[Polarity] Dev F1_macro: 0.7324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 6/30 [08:07<32:50, 82.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 7 | Train Loss: 0.2668\n",
            "[Entity] Dev F1_macro: 0.8951\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 7 | Train Loss: 0.4483\n",
            "[Polarity] Dev F1_macro: 0.7349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  23%|██▎       | 7/30 [09:30<31:32, 82.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 8 | Train Loss: 0.2634\n",
            "[Entity] Dev F1_macro: 0.8969\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 8 | Train Loss: 0.4311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 8/30 [10:45<29:21, 80.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7349\n",
            "[Entity] Epoch 9 | Train Loss: 0.2885\n",
            "[Entity] Dev F1_macro: 0.8985\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 9 | Train Loss: 0.4225\n",
            "[Polarity] Dev F1_macro: 0.7444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 9/30 [12:07<28:13, 80.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 10 | Train Loss: 0.3410\n",
            "[Entity] Dev F1_macro: 0.9009\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 10 | Train Loss: 0.4106\n",
            "[Polarity] Dev F1_macro: 0.7485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 10/30 [13:29<27:01, 81.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 11 | Train Loss: 0.3878\n",
            "[Entity] Dev F1_macro: 0.9032\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 11 | Train Loss: 0.4037\n",
            "[Polarity] Dev F1_macro: 0.7503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  37%|███▋      | 11/30 [14:54<26:00, 82.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 12 | Train Loss: 0.4496\n",
            "[Entity] Dev F1_macro: 0.8999\n",
            "[Polarity] Epoch 12 | Train Loss: 0.4185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 12/30 [16:07<23:52, 79.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7341\n",
            "[Entity] Epoch 13 | Train Loss: 0.3929\n",
            "[Entity] Dev F1_macro: 0.9095\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 13 | Train Loss: 0.3933\n",
            "[Polarity] Dev F1_macro: 0.7586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  43%|████▎     | 13/30 [17:29<22:42, 80.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 14 | Train Loss: 0.3777\n",
            "[Entity] Dev F1_macro: 0.9094\n",
            "[Polarity] Epoch 14 | Train Loss: 0.3531\n",
            "[Polarity] Dev F1_macro: 0.7754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 14/30 [18:44<20:56, 78.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 15 | Train Loss: 0.3689\n",
            "[Entity] Dev F1_macro: 0.9110\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 15 | Train Loss: 0.3135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 15/30 [19:59<19:21, 77.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7723\n",
            "[Entity] Epoch 16 | Train Loss: 0.3451\n",
            "[Entity] Dev F1_macro: 0.9108\n",
            "[Polarity] Epoch 16 | Train Loss: 0.3111\n",
            "[Polarity] Dev F1_macro: 0.7806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 16/30 [21:13<17:53, 76.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 17 | Train Loss: 0.3610\n",
            "[Entity] Dev F1_macro: 0.9126\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 17 | Train Loss: 0.3158\n",
            "[Polarity] Dev F1_macro: 0.7829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  57%|█████▋    | 17/30 [22:35<16:57, 78.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 18 | Train Loss: 0.3096\n",
            "[Entity] Dev F1_macro: 0.9119\n",
            "[Polarity] Epoch 18 | Train Loss: 0.2720\n",
            "[Polarity] Dev F1_macro: 0.7840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 18/30 [23:50<15:25, 77.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 19 | Train Loss: 0.2754\n",
            "[Entity] Dev F1_macro: 0.9134\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 19 | Train Loss: 0.2297\n",
            "[Polarity] Dev F1_macro: 0.8002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  63%|██████▎   | 19/30 [25:10<14:19, 78.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 20 | Train Loss: 0.2981\n",
            "[Entity] Dev F1_macro: 0.9136\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 20 | Train Loss: 0.2399\n",
            "[Polarity] Dev F1_macro: 0.8107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 20/30 [26:32<13:12, 79.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 21 | Train Loss: 0.2636\n",
            "[Entity] Dev F1_macro: 0.9129\n",
            "[Polarity] Epoch 21 | Train Loss: 0.2080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 21/30 [27:47<11:40, 77.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8104\n",
            "[Entity] Epoch 22 | Train Loss: 0.2629\n",
            "[Entity] Dev F1_macro: 0.9137\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 22 | Train Loss: 0.1815\n",
            "[Polarity] Dev F1_macro: 0.8254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 22/30 [29:08<10:31, 78.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 23 | Train Loss: 0.2841\n",
            "[Entity] Dev F1_macro: 0.9145\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 23 | Train Loss: 0.2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  77%|███████▋  | 23/30 [30:23<09:04, 77.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8236\n",
            "[Entity] Epoch 24 | Train Loss: 0.2563\n",
            "[Entity] Dev F1_macro: 0.9176\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 24 | Train Loss: 0.1693\n",
            "[Polarity] Dev F1_macro: 0.8259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 24/30 [31:46<07:54, 79.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 25 | Train Loss: 0.2231\n",
            "[Entity] Dev F1_macro: 0.9178\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 25 | Train Loss: 0.1391\n",
            "[Polarity] Dev F1_macro: 0.8339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [33:09<06:41, 80.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 26 | Train Loss: 0.2331\n",
            "[Entity] Dev F1_macro: 0.9160\n",
            "[Polarity] Epoch 26 | Train Loss: 0.1527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 26/30 [34:23<05:13, 78.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8310\n",
            "[Entity] Epoch 27 | Train Loss: 0.2435\n",
            "[Entity] Dev F1_macro: 0.9164\n",
            "[Polarity] Epoch 27 | Train Loss: 0.1421\n",
            "[Polarity] Dev F1_macro: 0.8347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [35:37<03:51, 77.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 28 | Train Loss: 0.2473\n",
            "[Entity] Dev F1_macro: 0.9160\n",
            "[Polarity] Epoch 28 | Train Loss: 0.1554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  93%|█████████▎| 28/30 [36:51<02:32, 76.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8307\n",
            "[Entity] Epoch 29 | Train Loss: 0.2207\n",
            "[Entity] Dev F1_macro: 0.9157\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 29 | Train Loss: 0.1518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  97%|█████████▋| 29/30 [38:04<01:15, 75.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8303\n",
            "[Entity] Epoch 30 | Train Loss: 0.2287\n",
            "[Entity] Dev F1_macro: 0.9166\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 30 | Train Loss: 0.1360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 30/30 [39:17<00:00, 78.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8303\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = jsonlload(test_data_path)\n",
        "test_sentiment_analysis(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktSAnbTwpYeP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749310454567,
          "user_tz": -540,
          "elapsed": 34596,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "f43c9961-940b-4150-fe83-0d11b375111a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sentiment Analysis Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence 값 분포 (ACD 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.6027\n",
            "  - mean: 0.9993\n",
            "  - median: 1.0000\n",
            "\n",
            "Confidence 값 분포 (ASC 단계):\n",
            "  - max: 0.9996\n",
            "  - min: 0.4095\n",
            "  - mean: 0.9644\n",
            "  - median: 0.9988\n",
            "\n",
            "F1 Evaluation Result:\n",
            "\n",
            "▶ ACD result\n",
            "   Precision: 0.9464\n",
            "   Recall: 0.9502\n",
            "   F1: 0.9483\n",
            "\n",
            "▶ entire ABSA result\n",
            "   Precision: 0.8889\n",
            "   Recall: 0.8854\n",
            "   F1: 0.8871\n",
            "\n",
            "Per-Aspect Performance:\n",
            "\n",
            " - 가격\n",
            "   ACD_Precision: 0.92\n",
            "   ACD_Recall: 0.9583\n",
            "   ACD_F1: 0.9388\n",
            "   ABSA_Precision: 0.8\n",
            "   ABSA_Recall: 0.8333\n",
            "   ABSA_F1: 0.8163\n",
            "   Support: 24\n",
            "\n",
            " - 거품\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9901\n",
            "   ACD_F1: 0.995\n",
            "   ABSA_Precision: 0.96\n",
            "   ABSA_Recall: 0.9505\n",
            "   ABSA_F1: 0.9552\n",
            "   Support: 101\n",
            "\n",
            " - 머릿결\n",
            "   ACD_Precision: 0.8947\n",
            "   ACD_Recall: 0.9808\n",
            "   ACD_F1: 0.9358\n",
            "   ABSA_Precision: 0.8421\n",
            "   ABSA_Recall: 0.9231\n",
            "   ABSA_F1: 0.8807\n",
            "   Support: 52\n",
            "\n",
            " - 세정\n",
            "   ACD_Precision: 0.9316\n",
            "   ACD_Recall: 0.916\n",
            "   ACD_F1: 0.9237\n",
            "   ABSA_Precision: 0.8718\n",
            "   ABSA_Recall: 0.8571\n",
            "   ABSA_F1: 0.8644\n",
            "   Support: 119\n",
            "\n",
            " - 없음\n",
            "   ACD_Precision: 0.0\n",
            "   ACD_Recall: 0.0\n",
            "   ACD_F1: 0.0\n",
            "   ABSA_Precision: 0\n",
            "   ABSA_Recall: 0\n",
            "   ABSA_F1: 0\n",
            "   Support: 0\n",
            "\n",
            " - 자극\n",
            "   ACD_Precision: 0.9474\n",
            "   ACD_Recall: 0.9\n",
            "   ACD_F1: 0.9231\n",
            "   ABSA_Precision: 0.8684\n",
            "   ABSA_Recall: 0.8049\n",
            "   ABSA_F1: 0.8354\n",
            "   Support: 40\n",
            "\n",
            " - 쿨링\n",
            "   ACD_Precision: 0.8667\n",
            "   ACD_Recall: 0.9286\n",
            "   ACD_F1: 0.8966\n",
            "   ABSA_Precision: 0.8667\n",
            "   ABSA_Recall: 0.9286\n",
            "   ABSA_F1: 0.8966\n",
            "   Support: 14\n",
            "\n",
            " - 탈모\n",
            "   ACD_Precision: 0.8696\n",
            "   ACD_Recall: 0.8333\n",
            "   ACD_F1: 0.8511\n",
            "   ABSA_Precision: 0.8261\n",
            "   ABSA_Recall: 0.7917\n",
            "   ABSA_F1: 0.8085\n",
            "   Support: 24\n",
            "\n",
            " - 향\n",
            "   ACD_Precision: 0.969\n",
            "   ACD_Recall: 0.9766\n",
            "   ACD_F1: 0.9728\n",
            "   ABSA_Precision: 0.907\n",
            "   ABSA_Recall: 0.8931\n",
            "   ABSA_F1: 0.9\n",
            "   Support: 128\n",
            "\n",
            "Average Loss:\n",
            " - ACD Loss: 0.8687\n",
            " - ASC Loss: 0.6594\n",
            "Saved predictions to /content/drive/MyDrive/ABSA/pred_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, dev_data = custom_stratified_KFold(input_file_list, 3, 2)"
      ],
      "metadata": {
        "id": "WRnp_qcTJimt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749310558737,
          "user_tz": -540,
          "elapsed": 473,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "24ffe8ec-f137-42ae-b3fa-4b8ece7f2f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomStratifiedKFold - 2/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentiment_analysis(train_data, dev_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJl9QdU0CdBs",
        "outputId": "6e79ea84-ea8b-416f-ef79-98f50be8cea4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749312589141,
          "user_tz": -540,
          "elapsed": 2029013,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentiment_analysis START\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Class Weights:\n",
            "  - False (class 0): weight = 1.2942\n",
            "  - True (class 1): weight = 4.3990\n",
            "Polarity Class Weights:\n",
            "  - positive (class 0): weight = 1.6674\n",
            "  - negative (class 1): weight = 3.8134\n",
            "  - neutral (class 2): weight = 7.2455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Epoch 1 | Train Loss: 0.5487\n",
            "[Entity] Dev F1_macro: 0.8647\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 1 | Train Loss: 0.8715\n",
            "[Polarity] Dev F1_macro: 0.6527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   3%|▎         | 1/30 [01:21<39:29, 81.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 2 | Train Loss: 0.3296\n",
            "[Entity] Dev F1_macro: 0.8710\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 2 | Train Loss: 0.6959\n",
            "[Polarity] Dev F1_macro: 0.6908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   7%|▋         | 2/30 [02:44<38:28, 82.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 3 | Train Loss: 0.3119\n",
            "[Entity] Dev F1_macro: 0.8703\n",
            "[Polarity] Epoch 3 | Train Loss: 0.6127\n",
            "[Polarity] Dev F1_macro: 0.7375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 3/30 [03:59<35:27, 78.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 4 | Train Loss: 0.2791\n",
            "[Entity] Dev F1_macro: 0.9014\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 4 | Train Loss: 0.5409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 4/30 [05:14<33:29, 77.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7216\n",
            "[Entity] Epoch 5 | Train Loss: 0.2709\n",
            "[Entity] Dev F1_macro: 0.9045\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 5 | Train Loss: 0.4826\n",
            "[Polarity] Dev F1_macro: 0.7591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  17%|█▋        | 5/30 [06:36<32:55, 79.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 6 | Train Loss: 0.2667\n",
            "[Entity] Dev F1_macro: 0.9094\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 6 | Train Loss: 0.4223\n",
            "[Polarity] Dev F1_macro: 0.7706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 6/30 [07:58<32:06, 80.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 7 | Train Loss: 0.2758\n",
            "[Entity] Dev F1_macro: 0.9129\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 7 | Train Loss: 0.3945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  23%|██▎       | 7/30 [09:13<30:05, 78.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7694\n",
            "[Entity] Epoch 8 | Train Loss: 0.3136\n",
            "[Entity] Dev F1_macro: 0.9149\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 8 | Train Loss: 0.3900\n",
            "[Polarity] Dev F1_macro: 0.7721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 8/30 [10:35<29:12, 79.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 9 | Train Loss: 0.4379\n",
            "[Entity] Dev F1_macro: 0.9195\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 9 | Train Loss: 0.3483\n",
            "[Polarity] Dev F1_macro: 0.7997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 9/30 [11:58<28:12, 80.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 10 | Train Loss: 0.4490\n",
            "[Entity] Dev F1_macro: 0.9217\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 10 | Train Loss: 0.3333\n",
            "[Polarity] Dev F1_macro: 0.8293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 10/30 [13:20<27:02, 81.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 11 | Train Loss: 0.4554\n",
            "[Entity] Dev F1_macro: 0.9211\n",
            "[Polarity] Epoch 11 | Train Loss: 0.3101\n",
            "[Polarity] Dev F1_macro: 0.8318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  37%|███▋      | 11/30 [14:35<25:04, 79.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 12 | Train Loss: 0.3926\n",
            "[Entity] Dev F1_macro: 0.9241\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 12 | Train Loss: 0.2897\n",
            "[Polarity] Dev F1_macro: 0.8462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 12/30 [15:58<24:04, 80.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 13 | Train Loss: 0.3222\n",
            "[Entity] Dev F1_macro: 0.9271\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 13 | Train Loss: 0.2324\n",
            "[Polarity] Dev F1_macro: 0.8644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  43%|████▎     | 13/30 [17:20<22:56, 80.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 14 | Train Loss: 0.3114\n",
            "[Entity] Dev F1_macro: 0.9274\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 14 | Train Loss: 0.1615\n",
            "[Polarity] Dev F1_macro: 0.8663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 14/30 [18:43<21:44, 81.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 15 | Train Loss: 0.2884\n",
            "[Entity] Dev F1_macro: 0.9272\n",
            "[Polarity] Epoch 15 | Train Loss: 0.1534\n",
            "[Polarity] Dev F1_macro: 0.8705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 15/30 [19:58<19:54, 79.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 16 | Train Loss: 0.2855\n",
            "[Entity] Dev F1_macro: 0.9265\n",
            "[Polarity] Epoch 16 | Train Loss: 0.1382\n",
            "[Polarity] Dev F1_macro: 0.8731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 16/30 [21:13<18:14, 78.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 17 | Train Loss: 0.2770\n",
            "[Entity] Dev F1_macro: 0.9270\n",
            "[Polarity] Epoch 17 | Train Loss: 0.1518\n",
            "[Polarity] Dev F1_macro: 0.8733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  57%|█████▋    | 17/30 [22:28<16:43, 77.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 18 | Train Loss: 0.2794\n",
            "[Entity] Dev F1_macro: 0.9286\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 18 | Train Loss: 0.1389\n",
            "[Polarity] Dev F1_macro: 0.8865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 18/30 [23:51<15:45, 78.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 19 | Train Loss: 0.2544\n",
            "[Entity] Dev F1_macro: 0.9291\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 19 | Train Loss: 0.1166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  63%|██████▎   | 19/30 [25:06<14:14, 77.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8815\n",
            "[Entity] Epoch 20 | Train Loss: 0.2535\n",
            "[Entity] Dev F1_macro: 0.9270\n",
            "[Polarity] Epoch 20 | Train Loss: 0.1270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 20/30 [26:20<12:45, 76.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8813\n",
            "[Entity] Epoch 21 | Train Loss: 0.2377\n",
            "[Entity] Dev F1_macro: 0.9283\n",
            "[Polarity] Epoch 21 | Train Loss: 0.1401\n",
            "[Polarity] Dev F1_macro: 0.8872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 21/30 [27:34<11:22, 75.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 22 | Train Loss: 0.2401\n",
            "[Entity] Dev F1_macro: 0.9301\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 22 | Train Loss: 0.1226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 22/30 [28:49<10:04, 75.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8754\n",
            "[Entity] Epoch 23 | Train Loss: 0.2341\n",
            "[Entity] Dev F1_macro: 0.9291\n",
            "[Polarity] Epoch 23 | Train Loss: 0.1246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  77%|███████▋  | 23/30 [30:03<08:45, 75.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8759\n",
            "[Entity] Epoch 24 | Train Loss: 0.2127\n",
            "[Entity] Dev F1_macro: 0.9300\n",
            "[Polarity] Epoch 24 | Train Loss: 0.1501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 24/30 [31:16<07:27, 74.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8774\n",
            "[Entity] Epoch 25 | Train Loss: 0.2068\n",
            "[Entity] Dev F1_macro: 0.9298\n",
            "[Polarity] Epoch 25 | Train Loss: 0.1420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [32:29<06:10, 74.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8832\n",
            "Early stopping triggered (Polarity)\n",
            "[Entity] Epoch 26 | Train Loss: 0.2064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [33:30<06:42, 80.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Dev F1_macro: 0.9292\n",
            "Early stopping triggered (Entity)\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = jsonlload(test_data_path)\n",
        "test_sentiment_analysis(test_data)"
      ],
      "metadata": {
        "id": "-YH2pkdoCfxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749312624186,
          "user_tz": -540,
          "elapsed": 35042,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "0ae11b6c-a1aa-44a7-8a82-3d619facee81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sentiment Analysis Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence 값 분포 (ACD 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.5060\n",
            "  - mean: 0.9993\n",
            "  - median: 1.0000\n",
            "\n",
            "Confidence 값 분포 (ASC 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.5086\n",
            "  - mean: 0.9900\n",
            "  - median: 0.9999\n",
            "\n",
            "F1 Evaluation Result:\n",
            "\n",
            "▶ ACD result\n",
            "   Precision: 0.9660\n",
            "   Recall: 0.9622\n",
            "   F1: 0.9641\n",
            "\n",
            "▶ entire ABSA result\n",
            "   Precision: 0.9300\n",
            "   Recall: 0.9190\n",
            "   F1: 0.9245\n",
            "\n",
            "Per-Aspect Performance:\n",
            "\n",
            " - 가격\n",
            "   ACD_Precision: 0.9583\n",
            "   ACD_Recall: 0.9583\n",
            "   ACD_F1: 0.9583\n",
            "   ABSA_Precision: 0.9167\n",
            "   ABSA_Recall: 0.9167\n",
            "   ABSA_F1: 0.9167\n",
            "   Support: 24\n",
            "\n",
            " - 거품\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9901\n",
            "   ACD_F1: 0.995\n",
            "   ABSA_Precision: 0.97\n",
            "   ABSA_Recall: 0.9604\n",
            "   ABSA_F1: 0.9652\n",
            "   Support: 101\n",
            "\n",
            " - 머릿결\n",
            "   ACD_Precision: 0.9091\n",
            "   ACD_Recall: 0.9615\n",
            "   ACD_F1: 0.9346\n",
            "   ABSA_Precision: 0.8727\n",
            "   ABSA_Recall: 0.9231\n",
            "   ABSA_F1: 0.8972\n",
            "   Support: 52\n",
            "\n",
            " - 세정\n",
            "   ACD_Precision: 0.9661\n",
            "   ACD_Recall: 0.958\n",
            "   ACD_F1: 0.962\n",
            "   ABSA_Precision: 0.9322\n",
            "   ABSA_Recall: 0.9244\n",
            "   ABSA_F1: 0.9283\n",
            "   Support: 119\n",
            "\n",
            " - 없음\n",
            "   ACD_Precision: 0.0\n",
            "   ACD_Recall: 0.0\n",
            "   ACD_F1: 0.0\n",
            "   ABSA_Precision: 0\n",
            "   ABSA_Recall: 0\n",
            "   ABSA_F1: 0\n",
            "   Support: 0\n",
            "\n",
            " - 자극\n",
            "   ACD_Precision: 0.9268\n",
            "   ACD_Recall: 0.95\n",
            "   ACD_F1: 0.9383\n",
            "   ABSA_Precision: 0.8537\n",
            "   ABSA_Recall: 0.8537\n",
            "   ABSA_F1: 0.8537\n",
            "   Support: 40\n",
            "\n",
            " - 쿨링\n",
            "   ACD_Precision: 0.8667\n",
            "   ACD_Recall: 0.9286\n",
            "   ACD_F1: 0.8966\n",
            "   ABSA_Precision: 0.8\n",
            "   ABSA_Recall: 0.8571\n",
            "   ABSA_F1: 0.8276\n",
            "   Support: 14\n",
            "\n",
            " - 탈모\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.8333\n",
            "   ACD_F1: 0.9091\n",
            "   ABSA_Precision: 0.95\n",
            "   ABSA_Recall: 0.7917\n",
            "   ABSA_F1: 0.8636\n",
            "   Support: 24\n",
            "\n",
            " - 향\n",
            "   ACD_Precision: 0.9843\n",
            "   ACD_Recall: 0.9766\n",
            "   ACD_F1: 0.9804\n",
            "   ABSA_Precision: 0.9606\n",
            "   ABSA_Recall: 0.9313\n",
            "   ABSA_F1: 0.9457\n",
            "   Support: 128\n",
            "\n",
            "Average Loss:\n",
            " - ACD Loss: 0.8130\n",
            " - ASC Loss: 0.8948\n",
            "Saved predictions to /content/drive/MyDrive/ABSA/pred_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, dev_data = custom_stratified_KFold(input_file_list, 3, 3)"
      ],
      "metadata": {
        "id": "Jnnmo3fWCiTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749312668254,
          "user_tz": -540,
          "elapsed": 342,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "cc29a08d-30ef-4cb3-f894-9520dff40068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomStratifiedKFold - 3/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentiment_analysis(train_data, dev_data)"
      ],
      "metadata": {
        "id": "iKtnL3dWCla1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749314881552,
          "user_tz": -540,
          "elapsed": 2212125,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "23ee9158-6334-4ca7-c07e-88ba28a8ff6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sentiment_analysis START\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (630 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity Class Weights:\n",
            "  - False (class 0): weight = 1.2986\n",
            "  - True (class 1): weight = 4.3485\n",
            "Polarity Class Weights:\n",
            "  - positive (class 0): weight = 1.6590\n",
            "  - negative (class 1): weight = 3.7500\n",
            "  - neutral (class 2): weight = 7.6603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Entity] Epoch 1 | Train Loss: 0.5300\n",
            "[Entity] Dev F1_macro: 0.8494\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 1 | Train Loss: 0.8637\n",
            "[Polarity] Dev F1_macro: 0.6143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   3%|▎         | 1/30 [01:21<39:32, 81.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 2 | Train Loss: 0.3234\n",
            "[Entity] Dev F1_macro: 0.8640\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 2 | Train Loss: 0.7051\n",
            "[Polarity] Dev F1_macro: 0.6407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   7%|▋         | 2/30 [02:44<38:29, 82.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 3 | Train Loss: 0.3053\n",
            "[Entity] Dev F1_macro: 0.8746\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 3 | Train Loss: 0.6304\n",
            "[Polarity] Dev F1_macro: 0.6815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 3/30 [04:05<36:41, 81.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 4 | Train Loss: 0.2760\n",
            "[Entity] Dev F1_macro: 0.8770\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 4 | Train Loss: 0.5950\n",
            "[Polarity] Dev F1_macro: 0.6978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  13%|█▎        | 4/30 [05:28<35:40, 82.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 5 | Train Loss: 0.2737\n",
            "[Entity] Dev F1_macro: 0.8840\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 5 | Train Loss: 0.5494\n",
            "[Polarity] Dev F1_macro: 0.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  17%|█▋        | 5/30 [06:51<34:19, 82.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 6 | Train Loss: 0.2717\n",
            "[Entity] Dev F1_macro: 0.8977\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 6 | Train Loss: 0.5275\n",
            "[Polarity] Dev F1_macro: 0.7133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 6/30 [08:13<32:59, 82.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 7 | Train Loss: 0.2862\n",
            "[Entity] Dev F1_macro: 0.9054\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 7 | Train Loss: 0.5086\n",
            "[Polarity] Dev F1_macro: 0.7358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  23%|██▎       | 7/30 [09:35<31:29, 82.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 8 | Train Loss: 0.3188\n",
            "[Entity] Dev F1_macro: 0.9082\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 8 | Train Loss: 0.4867\n",
            "[Polarity] Dev F1_macro: 0.7436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  27%|██▋       | 8/30 [10:57<30:07, 82.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 9 | Train Loss: 0.3615\n",
            "[Entity] Dev F1_macro: 0.9103\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 9 | Train Loss: 0.4082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 9/30 [12:11<27:53, 79.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7412\n",
            "[Entity] Epoch 10 | Train Loss: 0.4448\n",
            "[Entity] Dev F1_macro: 0.9141\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 10 | Train Loss: 0.3828\n",
            "[Polarity] Dev F1_macro: 0.7552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  33%|███▎      | 10/30 [13:34<26:50, 80.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 11 | Train Loss: 0.4594\n",
            "[Entity] Dev F1_macro: 0.9158\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 11 | Train Loss: 0.3731\n",
            "[Polarity] Dev F1_macro: 0.7764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  37%|███▋      | 11/30 [14:56<25:41, 81.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 12 | Train Loss: 0.4314\n",
            "[Entity] Dev F1_macro: 0.9134\n",
            "[Polarity] Epoch 12 | Train Loss: 0.3438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 12/30 [16:10<23:40, 78.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.7634\n",
            "[Entity] Epoch 13 | Train Loss: 0.4155\n",
            "[Entity] Dev F1_macro: 0.9177\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 13 | Train Loss: 0.2873\n",
            "[Polarity] Dev F1_macro: 0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  43%|████▎     | 13/30 [17:32<22:37, 79.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 14 | Train Loss: 0.3750\n",
            "[Entity] Dev F1_macro: 0.9183\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 14 | Train Loss: 0.2922\n",
            "[Polarity] Dev F1_macro: 0.8154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  47%|████▋     | 14/30 [18:55<21:31, 80.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 15 | Train Loss: 0.3368\n",
            "[Entity] Dev F1_macro: 0.9178\n",
            "[Polarity] Epoch 15 | Train Loss: 0.2527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 15/30 [20:08<19:39, 78.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8111\n",
            "[Entity] Epoch 16 | Train Loss: 0.3028\n",
            "[Entity] Dev F1_macro: 0.9188\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 16 | Train Loss: 0.1993\n",
            "[Polarity] Dev F1_macro: 0.8242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  53%|█████▎    | 16/30 [21:30<18:34, 79.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 17 | Train Loss: 0.3059\n",
            "[Entity] Dev F1_macro: 0.9191\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 17 | Train Loss: 0.2105\n",
            "[Polarity] Dev F1_macro: 0.8361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  57%|█████▋    | 17/30 [22:53<17:25, 80.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 18 | Train Loss: 0.2972\n",
            "[Entity] Dev F1_macro: 0.9209\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 18 | Train Loss: 0.1949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 18/30 [24:08<15:45, 78.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8351\n",
            "[Entity] Epoch 19 | Train Loss: 0.2875\n",
            "[Entity] Dev F1_macro: 0.9210\n",
            "Saved best entity model\n",
            "[Polarity] Epoch 19 | Train Loss: 0.1755\n",
            "[Polarity] Dev F1_macro: 0.8471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  63%|██████▎   | 19/30 [25:29<14:36, 79.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 20 | Train Loss: 0.2779\n",
            "[Entity] Dev F1_macro: 0.9206\n",
            "[Polarity] Epoch 20 | Train Loss: 0.1655\n",
            "[Polarity] Dev F1_macro: 0.8495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  67%|██████▋   | 20/30 [26:45<13:03, 78.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 21 | Train Loss: 0.2712\n",
            "[Entity] Dev F1_macro: 0.9201\n",
            "[Polarity] Epoch 21 | Train Loss: 0.1607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 21/30 [27:58<11:33, 77.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8439\n",
            "[Entity] Epoch 22 | Train Loss: 0.2577\n",
            "[Entity] Dev F1_macro: 0.9176\n",
            "[Polarity] Epoch 22 | Train Loss: 0.1728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  73%|███████▎  | 22/30 [29:12<10:07, 75.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8394\n",
            "[Entity] Epoch 23 | Train Loss: 0.2492\n",
            "[Entity] Dev F1_macro: 0.9204\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 23 | Train Loss: 0.1873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  77%|███████▋  | 23/30 [30:25<08:46, 75.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8443\n",
            "[Entity] Epoch 24 | Train Loss: 0.2306\n",
            "[Entity] Dev F1_macro: 0.9191\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 24 | Train Loss: 0.1629\n",
            "[Polarity] Dev F1_macro: 0.8526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 24/30 [31:39<07:28, 74.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best polarity model\n",
            "[Entity] Epoch 25 | Train Loss: 0.2366\n",
            "[Entity] Dev F1_macro: 0.9200\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 25 | Train Loss: 0.2034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  83%|████████▎ | 25/30 [32:53<06:12, 74.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8498\n",
            "[Entity] Epoch 26 | Train Loss: 0.2467\n",
            "[Entity] Dev F1_macro: 0.9209\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 26 | Train Loss: 0.1971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  87%|████████▋ | 26/30 [34:06<04:56, 74.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8448\n",
            "[Entity] Epoch 27 | Train Loss: 0.2550\n",
            "[Entity] Dev F1_macro: 0.9201\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 27 | Train Loss: 0.1641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [35:20<03:41, 73.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8506\n",
            "[Entity] Epoch 28 | Train Loss: 0.2382\n",
            "[Entity] Dev F1_macro: 0.9202\n",
            "Early stopping triggered (Entity)\n",
            "[Polarity] Epoch 28 | Train Loss: 0.1917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 27/30 [36:33<04:03, 81.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Polarity] Dev F1_macro: 0.8483\n",
            "Early stopping triggered (Polarity)\n",
            "Training complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = jsonlload(test_data_path)\n",
        "test_sentiment_analysis(test_data)"
      ],
      "metadata": {
        "id": "pLZQooAUJ455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749314916301,
          "user_tz": -540,
          "elapsed": 34747,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "95150f87-c5e3-48b0-cf6b-6fa041d434d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Sentiment Analysis Test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confidence 값 분포 (ACD 단계):\n",
            "  - max: 1.0000\n",
            "  - min: 0.6067\n",
            "  - mean: 0.9991\n",
            "  - median: 1.0000\n",
            "\n",
            "Confidence 값 분포 (ASC 단계):\n",
            "  - max: 0.9999\n",
            "  - min: 0.5312\n",
            "  - mean: 0.9889\n",
            "  - median: 0.9999\n",
            "\n",
            "F1 Evaluation Result:\n",
            "\n",
            "▶ ACD result\n",
            "   Precision: 0.9557\n",
            "   Recall: 0.9462\n",
            "   F1: 0.9510\n",
            "\n",
            "▶ entire ABSA result\n",
            "   Precision: 0.9115\n",
            "   Recall: 0.8953\n",
            "   F1: 0.9033\n",
            "\n",
            "Per-Aspect Performance:\n",
            "\n",
            " - 가격\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.9583\n",
            "   ACD_F1: 0.9787\n",
            "   ABSA_Precision: 0.9565\n",
            "   ABSA_Recall: 0.9167\n",
            "   ABSA_F1: 0.9362\n",
            "   Support: 24\n",
            "\n",
            " - 거품\n",
            "   ACD_Precision: 0.9899\n",
            "   ACD_Recall: 0.9703\n",
            "   ACD_F1: 0.98\n",
            "   ABSA_Precision: 0.9394\n",
            "   ABSA_Recall: 0.9208\n",
            "   ABSA_F1: 0.93\n",
            "   Support: 101\n",
            "\n",
            " - 머릿결\n",
            "   ACD_Precision: 0.8793\n",
            "   ACD_Recall: 0.9808\n",
            "   ACD_F1: 0.9273\n",
            "   ABSA_Precision: 0.7759\n",
            "   ABSA_Recall: 0.8654\n",
            "   ABSA_F1: 0.8182\n",
            "   Support: 52\n",
            "\n",
            " - 세정\n",
            "   ACD_Precision: 0.9558\n",
            "   ACD_Recall: 0.9076\n",
            "   ACD_F1: 0.931\n",
            "   ABSA_Precision: 0.9558\n",
            "   ABSA_Recall: 0.9076\n",
            "   ABSA_F1: 0.931\n",
            "   Support: 119\n",
            "\n",
            " - 없음\n",
            "   ACD_Precision: 0.0\n",
            "   ACD_Recall: 0.0\n",
            "   ACD_F1: 0.0\n",
            "   ABSA_Precision: 0\n",
            "   ABSA_Recall: 0\n",
            "   ABSA_F1: 0\n",
            "   Support: 0\n",
            "\n",
            " - 자극\n",
            "   ACD_Precision: 0.9268\n",
            "   ACD_Recall: 0.95\n",
            "   ACD_F1: 0.9383\n",
            "   ABSA_Precision: 0.878\n",
            "   ABSA_Recall: 0.878\n",
            "   ABSA_F1: 0.878\n",
            "   Support: 40\n",
            "\n",
            " - 쿨링\n",
            "   ACD_Precision: 1.0\n",
            "   ACD_Recall: 0.8571\n",
            "   ACD_F1: 0.9231\n",
            "   ABSA_Precision: 1.0\n",
            "   ABSA_Recall: 0.8571\n",
            "   ABSA_F1: 0.9231\n",
            "   Support: 14\n",
            "\n",
            " - 탈모\n",
            "   ACD_Precision: 0.8571\n",
            "   ACD_Recall: 0.75\n",
            "   ACD_F1: 0.8\n",
            "   ABSA_Precision: 0.7619\n",
            "   ABSA_Recall: 0.6667\n",
            "   ABSA_F1: 0.7111\n",
            "   Support: 24\n",
            "\n",
            " - 향\n",
            "   ACD_Precision: 0.9769\n",
            "   ACD_Recall: 0.9922\n",
            "   ACD_F1: 0.9845\n",
            "   ABSA_Precision: 0.9308\n",
            "   ABSA_Recall: 0.9237\n",
            "   ABSA_F1: 0.9272\n",
            "   Support: 128\n",
            "\n",
            "Average Loss:\n",
            " - ACD Loss: 0.9070\n",
            " - ASC Loss: 0.9003\n",
            "Saved predictions to /content/drive/MyDrive/ABSA/pred_result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Le8LWBcXJ7hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라벨링"
      ],
      "metadata": {
        "id": "ZGHJNHHqK8U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_raw_data_with_trained_model(\n",
        "    raw_data,\n",
        "    acd_best_model_path,\n",
        "    asc_best_model_path,\n",
        "    model_class,\n",
        "    acd_tokenizer_name,\n",
        "    asc_tokenizer_name,\n",
        "    tf_id_to_name,\n",
        "    polarity_id_to_name,\n",
        "    special_tokens_dict,\n",
        "    entity_property_pair,\n",
        "    max_len,\n",
        "    threshold,\n",
        "    save_path\n",
        "):\n",
        "    print(\"Starting Labeling with Raw Data...\")\n",
        "\n",
        "    try:\n",
        "        acd_tokenizer = AutoTokenizer.from_pretrained(acd_base_model)\n",
        "        acd_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "        asc_tokenizer = AutoTokenizer.from_pretrained(asc_base_model)\n",
        "        asc_tokenizer.add_special_tokens(special_tokens_dict)\n",
        "    except Exception as e:\n",
        "        print(f\"Tokenizer load error: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        acd_best_model = load_model(ABSA_Model, acd_best_model_path, acd_base_model, len(tf_id_to_name), len(acd_tokenizer))\n",
        "        asc_best_model = load_model(ABSA_Model, asc_best_model_path, asc_base_model, len(polarity_id_to_name), len(asc_tokenizer))\n",
        "    except Exception as e:\n",
        "        print(f\"Model load error: {e}\")\n",
        "        return\n",
        "\n",
        "    def predict_on_raw_data(data):\n",
        "        acd_best_model.eval()\n",
        "        asc_best_model.eval()\n",
        "        results = copy.deepcopy(data)\n",
        "\n",
        "        acd_pad_token_id = acd_tokenizer.pad_token_id\n",
        "        asc_pad_token_id = asc_tokenizer.pad_token_id\n",
        "\n",
        "        for idx, sentence in enumerate(tqdm(results, desc=\"라벨링 진행\")):\n",
        "            form = sentence.get('리뷰', '')\n",
        "            form = preprocessing(form)\n",
        "            sentence['annotation'] = []\n",
        "\n",
        "            if not isinstance(form, str) or not form.strip():\n",
        "                print(f\"Invalid sentence skipped: {form}\")\n",
        "                continue\n",
        "\n",
        "            for pair in entity_property_pair:\n",
        "                # ACD 수행\n",
        "                acd_encoded = acd_tokenizer(\n",
        "                    form,\n",
        "                    pair,\n",
        "                    padding=False,\n",
        "                    truncation=False,\n",
        "                    return_tensors='pt',\n",
        "                    add_special_tokens=True\n",
        "                )\n",
        "\n",
        "                acd_input_ids = acd_encoded['input_ids'][0].tolist()\n",
        "                acd_attention_mask = acd_encoded['attention_mask'][0].tolist()\n",
        "                acd_input_ids, acd_attention_mask = truncate_left(acd_input_ids, acd_attention_mask, max_len, acd_pad_token_id)\n",
        "\n",
        "                acd_input_ids = torch.tensor([acd_input_ids]).to(device)\n",
        "                acd_attention_mask = torch.tensor([acd_attention_mask]).to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    _, acd_logits = acd_best_model(acd_input_ids, acd_attention_mask)\n",
        "\n",
        "                acd_probs = torch.softmax(acd_logits, dim=-1)\n",
        "                acd_confidence, acd_pred = torch.max(acd_probs, dim=-1)\n",
        "                acd_pred = acd_pred.item()\n",
        "                acd_confidence = acd_confidence.item()\n",
        "\n",
        "                if tf_id_to_name[acd_pred] == 'True' and acd_confidence >= threshold:\n",
        "                    # ASC 수행\n",
        "                    asc_encoded = asc_tokenizer(\n",
        "                        form,\n",
        "                        pair,\n",
        "                        padding=False,\n",
        "                        truncation=False,\n",
        "                        return_tensors='pt',\n",
        "                        add_special_tokens=True\n",
        "                    )\n",
        "                    asc_input_ids = asc_encoded['input_ids'][0].tolist()\n",
        "                    asc_attention_mask = asc_encoded['attention_mask'][0].tolist()\n",
        "                    asc_input_ids, asc_attention_mask = truncate_left(asc_input_ids, asc_attention_mask, max_len, asc_pad_token_id)\n",
        "\n",
        "                    asc_input_ids = torch.tensor([asc_input_ids]).to(device)\n",
        "                    asc_attention_mask = torch.tensor([asc_attention_mask]).to(device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        _, asc_logits = asc_best_model(asc_input_ids, asc_attention_mask)\n",
        "\n",
        "                    asc_probs = torch.softmax(asc_logits, dim=-1)\n",
        "                    asc_confidence, asc_pred = torch.max(asc_probs, dim=-1)\n",
        "                    asc_pred = asc_pred.item()\n",
        "                    asc_confidence = asc_confidence.item()\n",
        "\n",
        "                    if 0 <= asc_pred < len(polarity_id_to_name):\n",
        "                        polarity = polarity_id_to_name[asc_pred]\n",
        "                    else:\n",
        "                        polarity = \"UNKNOWN\"\n",
        "\n",
        "                    sentence['annotation'].append([\n",
        "                        pair,\n",
        "                        [None, 0, 0],\n",
        "                        polarity\n",
        "                    ])\n",
        "\n",
        "            if not sentence['annotation']:\n",
        "                sentence['annotation'] = [[\"없음\", [None, 0, 0], None]]\n",
        "\n",
        "        return results\n",
        "\n",
        "    labeled_raw_data = predict_on_raw_data(raw_data)\n",
        "\n",
        "    if save_path:\n",
        "        try:\n",
        "            jsondump(labeled_raw_data, final_output_path)\n",
        "            print(f\"Saved final outputs to {save_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to save final outputs: {e}\")\n",
        "\n",
        "    return labeled_raw_data"
      ],
      "metadata": {
        "id": "rK5FqwH3K94S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jsonlload(raw_data_path)"
      ],
      "metadata": {
        "id": "2lEsRs84eHHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = jsonlload(raw_data_path)\n",
        "len(raw_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o-mziVfmq5P",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749387476330,
          "user_tz": -540,
          "elapsed": 3960,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "3efa249f-5378-42ec-bf7b-3fff6e15bb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "181908"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled = label_raw_data_with_trained_model(\n",
        "    raw_data=jsonlload(raw_data_path),\n",
        "    acd_best_model_path=acd_best_model_path,\n",
        "    asc_best_model_path=asc_best_model_path,\n",
        "    model_class=ABSA_Model,\n",
        "    acd_tokenizer_name=acd_base_model,\n",
        "    asc_tokenizer_name=asc_base_model,\n",
        "    tf_id_to_name=tf_id_to_name,\n",
        "    polarity_id_to_name=polarity_id_to_name,\n",
        "    special_tokens_dict=special_tokens_dict,\n",
        "    entity_property_pair=entity_property_pair,\n",
        "    max_len=max_len,\n",
        "    threshold=threshold,\n",
        "    save_path=final_output_DIR\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641,
          "referenced_widgets": [
            "d37468fef1af4bf1a575f5041db5e177",
            "c5c2a863c3a54b7392d41e323ffaae21",
            "511daa1008cd43e18ebe3ee3558fa7db",
            "be23fe76b1f64ac394cde0ead91aea91",
            "ea8b99c295eb43baad3de8283967aad5",
            "6b762fecdd884c8689c628f048c4e373",
            "1619167021f2478dbaade5e348e76c99",
            "e8538d4116904957b659ed248947c568",
            "1aac2ae4cc154d5e99ccb67d591a10d6",
            "9fe4ea403f8a4a618dcec7c644e42143",
            "d3f5c4b4e9b9413986214ca7286d3344",
            "8bc414880c144eac98a3829d8c897367",
            "8d065c6f44c1479ab4f778b2f4cf3ab9",
            "b4e1c99d8b7048cc8d854b09979fc8f1",
            "a8dfebeed11f4b878098cfe4b9595f7d",
            "0615c2eb2f5f4daca3cc91da4e182414",
            "d2976a99d05a4a438279c51718d3553c",
            "e96f23076fff4b1e903d619105baae1d",
            "e531b07a3fd3448ab2d8e50260cac5af",
            "7bd94660d59d4382acc1a6f02f736a12",
            "2ef2467af6494dc3a9aa45f149f3194c",
            "1abad9038f9344a4b7737c59ea4335ee",
            "80c80c6d6abe49f9be66fa7404fabce2",
            "cb621755c294497281cbc9880f1954b7",
            "320e153516f440ceaacef764cf52334f",
            "493fa382c1e849a9b9bc0528be59128d",
            "c5d9ec9adaf948c286adc13d6df6ea4b",
            "730d88ffe3d949ccb2f9f8d5bad50f2d",
            "9076d48a92ab48089c40d1d37535e6f1",
            "d0b839e91fb44c24aa4be4e5edfde835",
            "a989a000c08b4292bd780d8a8b112f72",
            "3c21a6ec3e634771ad281f68ad7aaff0",
            "f7ba788ac5fa4f48a52cd0c7eb529b62",
            "9ff8fd9ad6bb41539e93a8e7e626a879",
            "9b1fe92053b64cf8a5424a15587c2f7a",
            "17dc0de1b8d54f0280b4cf40a9fa6dfa",
            "4374beffdd7d49d0b13ed837d2c9a896",
            "668c5407a7f74b538d5439fb4fd8f942",
            "e9999aeae9304b20bf95c3d896a748ab",
            "a24cc7d342c745909f4b9c2df5d59971",
            "816d8f15d4c7494cb69d6c905dac9b90",
            "65de6d5eb4d74abcabb1abcad20f4fa0",
            "9de6d7291d4e4694932c813ab70e6eae",
            "2513cbc02a6c401a88d7b9d5e7e8286d",
            "fa1d8153a86845dfa55e52389848e002",
            "50126d3ae50b4c8c9f4c8b78016cd6f3",
            "6af50ce3dd43484e8621a282493dcf31",
            "a0e166a1fec24cf19032538de9b26aab",
            "bb86ec72f9c54e8194d6ef028540ff31",
            "bbe0e98f64af40cc988c733289da64cd",
            "b08d9bd9d7c84e0dbfab714b68387be5",
            "df8190d8430e476aa517b602dd6981e3",
            "527ba66864bd4832bbcd856095d25d77",
            "6121f2e8a8a14553990658e9b3b7fb12",
            "6cbe447bf49f4792a1f9ce28d94fb443",
            "ddf4b374035542e29ff412d4b03fdb4f",
            "633923446b5a48e8a2c246d269ed3e0b",
            "0a5bc613b62b4a1ea9b204ae9a13e8dc",
            "ef837885c66e4a018788728e6d0ab2c2",
            "851cb2e362254c8c844712abe5401915",
            "653a7e58c88d497a8a2b7a7142443dec",
            "78ccef5abf46451d920f33e6dc76461a",
            "338217c459814659b342c52761253461",
            "c26cef2efbc640e9bc8bf9f685633403",
            "defbd82c64e146b6a892a9c4ee7e8394",
            "424df52f00d0429fb5904e5258b558b7",
            "078765e4ac7a45c699b73df65d195d67",
            "46fa5fdc61be4ed491493cbd0945e12d",
            "81235b48bcef4f5899f1e729fe695ad1",
            "ece7db3a1da44acfa33ccbfcbd89d2a6",
            "232810a399ca4457b1fe058156dc2230",
            "348775353816488b97a299b920e9bc53",
            "4069eed85e154984a6db44037acfcac8",
            "f20953ce17bd40f4874824f87caeb830",
            "595d1c3c24b4411c90339002bcbaecfe",
            "956260fe42ab4e249240200cda76d60e",
            "e9f1e38a08874798bf02bd7976fecb91",
            "ee75a328630a4d67ba91918c8f8ef410",
            "3df01e0ec1184604851d8507e74a4af2",
            "9521804e04f34e0f8cc499e874b87d3a",
            "c867a562fda844abab76fd00ca85bce5",
            "4f92db84db6c4c9fb00a4befadcd13c7",
            "f2e23d527f784cf587efe71f44521aaf",
            "c64ec0daeb854304b6e3b93631fd2f7d",
            "6dca3ee59da64fb6bcfb9af5ddc529a2",
            "e149c2c1ab224d29847b95e849da5233",
            "c706cf3d2b2542d8997e794fb79a4b22",
            "cbeb9941dedc4c74b549048dd06c1ecc",
            "c94d8f512f104167bf410318dd3cbef6",
            "2e4cd618bcc645ac835206effbb856b0",
            "b1a770f214dc41a9a600e90fa55b4f5b",
            "27623fd199114adfaa6705ff32def032",
            "9ee70976c1ee47e5b1a2b63d51b9d7c0",
            "73d68938e32543bc934c958cd3182df4",
            "4c48c2aafc85437fb5e834605771d75b",
            "f92427b4322c4640b72b07a344500473",
            "fa3e7cd8cc454a54b623b06dd03514c9",
            "973ecef43ed44b0da62ef0c4d3aa8aca",
            "ab8d86b5c5cb4a5ea65476cb60991118",
            "c996b73ce3474a2d8ca4dfc9187d0115",
            "14acabc7b10945f3b9fe7e9925fb8b81",
            "59c0a2305d0b47f89c66e585ea9197c0",
            "92092897943f49eaadf871f0d7c226ed",
            "ea7d758170bd495b9f1188613f0c159f",
            "408fb3425ad8402ba60b023175264599",
            "a8b5c0db24bc4047a9445077d711364d",
            "c6626354d22a4aaeada164e619d32783",
            "a5e2c3dd0c5b4cbd9d3ac26da28546c9",
            "ab2f76647ff243228f5fc3c41184f0c1",
            "68586f178e024a6aa5f9e05004650f58",
            "57fbf238c7c647e3a6a281b0fb11e9fc",
            "fbb4457a99784a78a67073b7a3dee446",
            "d1a1343857e34bd8adec56a67b63468f",
            "0884878b27ed4b4ca234dcb9935b76d2",
            "e326a04a55674ed78447e11984d9ef33",
            "b679cf66bc884f81a43d0b1c79f7d811",
            "02da67776af2461b8131e8ecdbe4e8c1",
            "f1e6fef0e35e4a8c873ae40f8fd9de54",
            "c0e1305f0f574a1eab0f766af6741b12",
            "d6c2841b156e42618de3de827e788504",
            "c498f69acdd04d47abf574ef7eef84d8"
          ]
        },
        "id": "XF8C9egMMS3j",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1749406574965,
          "user_tz": -540,
          "elapsed": 19060545,
          "user": {
            "displayName": "melon",
            "userId": "16479606032837208631"
          }
        },
        "outputId": "09ac63bc-c59c-4726-f652-8256032836e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Labeling with Raw Data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/80.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d37468fef1af4bf1a575f5041db5e177"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bc414880c144eac98a3829d8c897367"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/344k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80c80c6d6abe49f9be66fa7404fabce2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ff8fd9ad6bb41539e93a8e7e626a879"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa1d8153a86845dfa55e52389848e002"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddf4b374035542e29ff412d4b03fdb4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "078765e4ac7a45c699b73df65d195d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee75a328630a4d67ba91918c8f8ef410"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/473M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c94d8f512f104167bf410318dd3cbef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c996b73ce3474a2d8ca4dfc9187d0115"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57fbf238c7c647e3a6a281b0fb11e9fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "라벨링 진행:   1%|          | 1407/181908 [02:25<5:57:29,  8.42it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "라벨링 진행:   2%|▏         | 2879/181908 [04:53<5:28:10,  9.09it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "라벨링 진행: 100%|██████████| 181908/181908 [5:16:33<00:00,  9.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved final outputs to /content/drive/MyDrive/ABSA/f_final_output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YW-Bg1bDLH2R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}